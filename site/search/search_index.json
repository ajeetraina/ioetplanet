{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to IoETPlanet","text":""},{"location":"#raspberry-pi","title":"Raspberry Pi","text":"<ul> <li>Getting Started with Raspberry Pi</li> <li>Install Docker on Raspberry Pi</li> <li>The Pico Project</li> <li>Using GPS Module</li> </ul>"},{"location":"#nvidia-jetson-nano","title":"NVIDIA Jetson Nano","text":"<ul> <li>Getting Started with NVIDIA Jetson Nano</li> <li>Getting Started with Docker on Jetson Nano</li> <li>BME Sensor Analytics using Redis TimeSeries, Grafana and Docker</li> <li>OLED Display using Groove on Jetson Nano</li> </ul>"},{"location":"#nvidia-jetson-xavier-agx","title":"NVIDIA Jetson Xavier AGX","text":"<ul> <li>Getting Started with NVIDIA Jetson Xavier</li> <li>Docker on NVIDIA Jetson Xavier AGX</li> </ul>"},{"location":"#tello-drone","title":"Tello Drone","text":"<ul> <li>Getting Started with DJI Tello Drone</li> <li>Control DJI Tello Drone using Python</li> </ul>"},{"location":"#dji-robomaster-s1","title":"DJI Robomaster S1","text":"<ul> <li>Getting Started with Robomaster</li> </ul>"},{"location":"nvidia/docker-on-jetson-nano/","title":"Getting Started with Docker on  NVIDIA Jetson Nano","text":""},{"location":"nvidia/docker-on-jetson-nano/#verifying-if-it-is-shipped-with-docker-binaries","title":"Verifying if it is shipped with Docker Binaries","text":"<pre><code>ajeetraina@ajeetraina-desktop:~$ sudo docker version\n[sudo] password for ajeetraina: \nClient:\n Version:           19.03.6\n API version:       1.40\n Go version:        go1.12.17\n Git commit:        369ce74a3c\n Built:             Fri Feb 28 23:47:53 2020\n OS/Arch:           linux/arm64\n Experimental:      false\n\nServer:\n Engine:\n  Version:          19.03.6\n  API version:      1.40 (minimum version 1.12)\n  Go version:       go1.12.17\n  Git commit:       369ce74a3c\n  Built:            Wed Feb 19 01:06:16 2020\n  OS/Arch:          linux/arm64\n  Experimental:     false\n containerd:\n  Version:          1.3.3-0ubuntu1~18.04.2\n  GitCommit:        \n runc:\n  Version:          spec: 1.0.1-dev\n  GitCommit:        \n docker-init:\n  Version:          0.18.0\n  GitCommit:       \n</code></pre>"},{"location":"nvidia/docker-on-jetson-nano/#checking-docker-runtime","title":"Checking Docker runtime","text":"<p>Starting with JetPack 4.2, NVIDIA has introduced a container runtime with Docker integration. This custom runtime enables Docker containers to access the underlying GPUs available in the Jetson family.</p> <pre><code>pico@pico1:/tmp/docker-build$ sudo nvidia-docker version\nNVIDIA Docker: 2.0.3\nClient:\n Version:           19.03.6\n API version:       1.40\n Go version:        go1.12.17\n Git commit:        369ce74a3c\n Built:             Fri Feb 28 23:47:53 2020\n OS/Arch:           linux/arm64\n Experimental:      false\n\nServer:\n Engine:\n  Version:          19.03.6\n  API version:      1.40 (minimum version 1.12)\n  Go version:       go1.12.17\n  Git commit:       369ce74a3c\n  Built:            Wed Feb 19 01:06:16 2020\n  OS/Arch:          linux/arm64\n  Experimental:     false\n containerd:\n  Version:          1.3.3-0ubuntu1~18.04.2\n  GitCommit:        \n runc:\n  Version:          spec: 1.0.1-dev\n  GitCommit:        \n docker-init:\n  Version:          0.18.0\n  GitCommit:\n</code></pre>"},{"location":"nvidia/docker-on-jetson-nano/#installing-docker-compose-on-nvidia-jetson-nano","title":"Installing Docker Compose on NVIDIA Jetson Nano","text":"<p>Jetson Nano doesnt come with Docker Compose installed by default. You will need to install it first:</p> <pre><code>export DOCKER_COMPOSE_VERSION=1.27.4\nsudo apt-get install libhdf5-dev\nsudo apt-get install libssl-dev\nsudo pip3 install docker-compose==\"${DOCKER_COMPOSE_VERSION}\"\napt install python3\napt install python3-pip\npip install docker-compose\n</code></pre> <pre><code>docker-compose version\ndocker-compose version 1.26.2, build unknown\ndocker-py version: 4.3.1\nCPython version: 3.6.9\nOpenSSL version: OpenSSL 1.1.1  11 Sep 2018\n</code></pre> <p>Next, add default runtime for NVIDIA:</p> <p>Edit /etc/docker/daemon.json</p> <pre><code>{\n    \"runtimes\": {\n        \"nvidia\": {\n            \"path\": \"/usr/bin/nvidia-container-runtime\",\n            \"runtimeArgs\": []\n        }\n    },\n\n    \"default-runtime\": \"nvidia\",\n    \"node-generic-resources\": [ \"NVIDIA-GPU=0\" ]\n}\n\n</code></pre> <p>Restart the Docker Daemon</p> <pre><code>systemctl restart docker\n</code></pre>"},{"location":"nvidia/docker-on-jetson-nano/#identify-the-jetson-board","title":"Identify the Jetson board","text":"<pre><code>pico@pico1:~$ git clone https://github.com/jetsonhacks/jetsonUtilities\nCloning into 'jetsonUtilities'...\nremote: Enumerating objects: 123, done.\nremote: Counting objects: 100% (39/39), done.\nremote: Compressing objects: 100% (30/30), done.\nremote: Total 123 (delta 15), reused 23 (delta 8), pack-reused 84\nReceiving objects: 100% (123/123), 32.87 KiB | 5.48 MiB/s, done.\nResolving deltas: 100% (49/49), done.\npico@pico1:~$ cd jetson\n-bash: cd: jetson: No such file or directory\npico@pico1:~$ cd jetsonUtilities/\n</code></pre> <pre><code>pico@pico1:~/jetsonUtilities$ ls\nLICENSE  README.md  jetsonInfo.py  scripts\n\npico@pico1:~/jetsonUtilities$ python3 jetsonInfo.py \nNVIDIA Jetson Nano (Developer Kit Version)\n L4T 32.4.4 [ JetPack 4.4.1 ]\n   Ubuntu 18.04.5 LTS\n   Kernel Version: 4.9.140-tegra\n CUDA 10.2.89\n   CUDA Architecture: 5.3\n OpenCV version: 4.1.1\n   OpenCV Cuda: NO\n CUDNN: 8.0.0.180\n TensorRT: 7.1.3.0\n Vision Works: 1.6.0.501\n VPI: 4.4.1-b50\n Vulcan: 1.2.70\n</code></pre>"},{"location":"nvidia/docker-on-jetson-nano/#install-the-latest-version-of-cuda","title":"Install the latest version of CUDA","text":"<pre><code>wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/sbsa/cuda-ubuntu1804.pin\nsudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\nwget https://developer.download.nvidia.com/compute/cuda/11.3.1/local_installers/cuda-repo-ubuntu1804-11-3-local_11.3.1-465.19.01-1_arm64.deb\nsudo dpkg -i cuda-repo-ubuntu1804-11-3-local_11.3.1-465.19.01-1_arm64.deb\nsudo apt-key add /var/cuda-repo-ubuntu1804-11-3-local/7fa2af80.pub\nsudo apt-get update\nsudo apt-get -y install cuda\n</code></pre>"},{"location":"nvidia/docker-on-jetson-nano/#verify-docker-runtime","title":"Verify Docker runtime","text":"<pre><code>docker info | grep runtime\n Runtimes: nvidia runc io.containerd.runc.v2 io.containerd.runtime.v1.linux\n</code></pre>"},{"location":"nvidia/docker-on-jetson-nano/#testing-gpu-support","title":"Testing GPU Support","text":"<p>We\u2019ll use the deviceQuery NVIDIA test application (included in L4T) to check that we can access the GPU in the cluster. First, we\u2019ll create a Docker image with the appropriate software, run it directly as Docker, then run it using containerd ctr and finally on the Kubernetes cluster itself.</p>"},{"location":"nvidia/docker-on-jetson-nano/#running-devicequery-on-docker-with-gpu-support","title":"Running deviceQuery on Docker with GPU support","text":""},{"location":"nvidia/docker-on-jetson-nano/#create-a-directory","title":"Create a directory","text":"<pre><code>mkdir test\ncd test\n</code></pre>"},{"location":"nvidia/docker-on-jetson-nano/#copy-the-sample-files","title":"Copy the sample files","text":"<p>Copy the demos where deviceQuery is located to the working directory where the Docker image will be created:</p> <pre><code>cp -R /usr/local/cuda/samples .\n</code></pre>"},{"location":"nvidia/docker-on-jetson-nano/#create-a-dockerfile","title":"Create a Dockerfile","text":"<pre><code>FROM nvcr.io/nvidia/l4t-base:r32.5.0\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends make g++\nCOPY ./samples /tmp/samples\nWORKDIR /tmp/samples/1_Utilities/deviceQuery\nRUN make clean &amp;&amp; make\nCMD [\"./deviceQuery\"]\n</code></pre> <pre><code>sudo docker build -t ajeetraina/jetson_devicequery . -f Dockerfile\n</code></pre> <pre><code>pico@pico2:~/test$ sudo docker run --rm --runtime nvidia ajeetraina/jetson_devicequery:latest\n./deviceQuery Starting...\n\n CUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"NVIDIA Tegra X1\"\n  CUDA Driver Version / Runtime Version          10.2 / 10.2\n  CUDA Capability Major/Minor version number:    5.3\n  Total amount of global memory:                 3963 MBytes (4155383808 bytes)\n  ( 1) Multiprocessors, (128) CUDA Cores/MP:     128 CUDA Cores\n  GPU Max Clock rate:                            922 MHz (0.92 GHz)\n  Memory Clock rate:                             13 Mhz\n  Memory Bus Width:                              64-bit\n  L2 Cache Size:                                 262144 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 32768\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            Yes\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device supports Compute Preemption:            No\n  Supports Cooperative Kernel Launch:            No\n  Supports MultiDevice Co-op Kernel Launch:      No\n  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 0\n  Compute Mode:\n     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.2, CUDA Runtime Version = 10.2, NumDevs = 1\nResult = PASS\n</code></pre> <p>Test 2: Running deviceQuery on containerd with GPU support</p> <p>Since K3s uses containerd as its runtime by default, we will use the ctr command line to test and deploy the deviceQuery image we pushed on containerd with this script:</p> <pre><code>#!/bin/bash\nIMAGE=ajeetraina/jetson_devicequery:latest\nexport KUBECONFIG=/etc/rancher/k3s/k3s.yaml\nctr i pull docker.io/${IMAGE}\nctr run --rm --gpus 0 --tty docker.io/${IMAGE} deviceQuery\n</code></pre>"},{"location":"nvidia/docker-on-jetson-nano/#execute-the-script","title":"Execute the script","text":"<pre><code>sudo sh usectr.sh\n</code></pre> <pre><code>sudo sh usectr.sh \ndocker.io/ajeetraina/jetson_devicequery:latest:                                   resolved       |++++++++++++++++++++++++++++++++++++++| \nmanifest-sha256:dfeaad4046f78871d3852e5d5fb8fa848038c57c34c6554c6c97a00ba120d550: done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:4438ebff930fb27930d802553e13457783ca8a597e917c030aea07f8ff6645c0:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:b1cdeb9e69c95684d703cf96688ed2b333a235d5b33f0843663ff15f62576bd4:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:bf60857fb4964a3e3ce57a900bbe47cd1683587d6c89ecbce4af63f98df600aa:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:0aac5305d11a81f47ed76d9663a8d80d2963b61c643acfce0515f0be56f5e301:    done           |++++++++++++++++++++++++++++++++++++++| \nconfig-sha256:37987db6d6570035e25e713f41e665a6d471d25056bb56b4310ed1cb1d79a100:   done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:f0f57d03cad8f8d69b1addf90907b031ccb253b5a9fc5a11db83c51aa311cbfb:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:08c23323368d4fde5347276d543c500e1ff9b712024ca3f85172018e9440d8b0:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:04da93b342eb651d6b94c74a934a3290697573a907fa0a06067b538095601745:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:f84ceb6e8887e9b3b454813459ee97c2b9730869dbd37d4cca4051958b7a5a36:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:93752947af53e2a3225e145b359b956df36e20521b5dde0fe6d3fb92fd2a9538:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:b235194751dee33624fc154603f7e25ecdfbb02538fb7d55fa796df9afa95fee:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:905b1329c1d473c79650e33b882d980b3522fb72e58ecd3456c4fb3c4039fe92:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:8931d5ba88b488c949f77f990e8f9198b153ceb71afd0369eac9c39beb38f2d6:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:cfb2938be99fb944fe31165bdf44532a5536865ce53b12eb7758d1e2a51ad33e:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:606a67bb8db9a1111022bdc6406442e11c1a66653136c5c777114bf67b61038a:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:2f37138d1c8ac71d9314a0f8996ba69579bbc6ee6a57440557bc7eef486ed292:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:9ce7ce1da17c2b8149573d1d73132f61a73083f0cd498eeb7a0da404fd77db14:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:a36863a728ec9221c83c745f40511946dfd63beca0f10c9afcc774ef7a98e420:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:86dd6e5994e2c15f2783d8d543327479ccee7f3b20023dd962fdb9a211071e16:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:f5299db1221c515de91f59d84b79f2f839f9c94a5d0cc7fad04134e23ec9b88a:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:15a5811e1a7bf377cbac066b04e0b36b4c1a41ca63eb3c67c17b734577f6beea:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:cb893097de39451407d7167b312ec56eaea80baa041877af8239dbe833fa044b:    done           |++++++++++++++++++++++++++++++++++++++| \nelapsed: 81.4s                                                                    total:  305.5  (3.8 MiB/s)                                       \nunpacking linux/arm64/v8 sha256:dfeaad4046f78871d3852e5d5fb8fa848038c57c34c6554c6c97a00ba120d550...\n\ndone\n\n./deviceQuery Starting...\n\n CUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"NVIDIA Tegra X1\"\n  CUDA Driver Version / Runtime Version          10.2 / 10.2\n  CUDA Capability Major/Minor version number:    5.3\n  Total amount of global memory:                 3963 MBytes (4155383808 bytes)\n  ( 1) Multiprocessors, (128) CUDA Cores/MP:     128 CUDA Cores\n  GPU Max Clock rate:                            922 MHz (0.92 GHz)\n  Memory Clock rate:                             13 Mhz\n  Memory Bus Width:                              64-bit\n  L2 Cache Size:                                 262144 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 32768\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            Yes\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device supports Compute Preemption:            No\n  Supports Cooperative Kernel Launch:            No\n  Supports MultiDevice Co-op Kernel Launch:      No\n  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 0\n  Compute Mode:\n     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.2, CUDA Runtime Version = 10.2, NumDevs = 1\nResult = PASS\n\n\n</code></pre>"},{"location":"nvidia/docker-on-jetson-nano/#test-3-running-devicequery-on-the-k3s-cluster","title":"Test 3: Running deviceQuery on the K3s cluster","text":"<pre><code>pico@pico2:~/test$ cat pod_deviceQuery.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: devicequery\nspec:\n  containers:\n    - name: nvidia\n      image: ajeetraina/jetson_devicequery:latest\n\n      command: [ \"./deviceQuery\" ]\npico@pico2:~/test$\n</code></pre> <pre><code>sudo KUBECONFIG=/etc/rancher/k3s/k3s.yaml kubectl apply -f ./pod_deviceQuery.yaml\npod/devicequery created\n</code></pre> <pre><code>pico@pico2:~/test$ sudo KUBECONFIG=/etc/rancher/k3s/k3s.yaml kubectl describe pod devicequery\nName:         devicequery\nNamespace:    default\nPriority:     0\nNode:         pico4/192.168.1.163\nStart Time:   Sun, 13 Jun 2021 09:16:44 -0700\nLabels:       &lt;none&gt;\nAnnotations:  &lt;none&gt;\nStatus:       Pending\nIP:           \nIPs:          &lt;none&gt;\nContainers:\n  nvidia:\n    Container ID:  \n    Image:         ajeetraina/jetson_devicequery:latest\n    Image ID:      \n    Port:          &lt;none&gt;\n    Host Port:     &lt;none&gt;\n    Command:\n      ./deviceQuery\n    State:          Waiting\n      Reason:       ContainerCreating\n    Ready:          False\n    Restart Count:  0\n    Environment:    &lt;none&gt;\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-mcrmv (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             False \n  ContainersReady   False \n  PodScheduled      True \nVolumes:\n  kube-api-access-mcrmv:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       &lt;nil&gt;\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              &lt;none&gt;\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  78s   default-scheduler  Successfully assigned default/devicequery to pico4\n  Normal  Pulling    77s   kubelet            Pulling image \"ajeetraina/jetson_devicequery:latest\"\npico@pico2:~/test$\n</code></pre> <pre><code>cat pod_deviceQuery_jetson4.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: devicequery\nspec:\n  nodeName: pico4\n  containers:\n    - name: nvidia\n      image: ajeetraina/jetson_devicequery:latest\n      command: [ \"./deviceQuery\" ]\npico@pico2:~/test$ \n</code></pre> <pre><code>pico@pico2:~/test$ sudo KUBECONFIG=/etc/rancher/k3s/k3s.yaml kubectl describe pod devicequery\nName:         devicequery\nNamespace:    default\nPriority:     0\nNode:         pico4/192.168.1.163\nStart Time:   Sun, 13 Jun 2021 09:16:44 -0700\nLabels:       &lt;none&gt;\nAnnotations:  &lt;none&gt;\nStatus:       Running\nIP:           10.42.1.3\nIPs:\n  IP:  10.42.1.3\nContainers:\n  nvidia:\n    Container ID:  containerd://fd502d6bfa55e2f80b2d50bc262e6d6543fd8d09e9708bb78ecec0b2e09621c3\n    Image:         ajeetraina/jetson_devicequery:latest\n    Image ID:      docker.io/ajeetraina/jetson_devicequery@sha256:dfeaad4046f78871d3852e5d5fb8fa848038c57c34c6554c6c97a00ba120d550\n    Port:          &lt;none&gt;\n    Host Port:     &lt;none&gt;\n    Command:\n      ./deviceQuery\n    State:          Waiting\n      Reason:       CrashLoopBackOff\n    Last State:     Terminated\n      Reason:       Error\n      Exit Code:    1\n      Started:      Sun, 13 Jun 2021 09:21:50 -0700\n      Finished:     Sun, 13 Jun 2021 09:21:50 -0700\n    Ready:          False\n    Restart Count:  5\n    Environment:    &lt;none&gt;\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-mcrmv (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             False \n  ContainersReady   False \n  PodScheduled      True \nVolumes:\n  kube-api-access-mcrmv:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       &lt;nil&gt;\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              &lt;none&gt;\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type     Reason     Age                    From               Message\n  ----     ------     ----                   ----               -------\n  Normal   Scheduled  7m51s                  default-scheduler  Successfully assigned default/devicequery to pico4\n  Normal   Pulled     5m45s                  kubelet            Successfully pulled image \"ajeetraina/jetson_devicequery:latest\" in 2m5.699757621s\n  Normal   Pulled     5m43s                  kubelet            Successfully pulled image \"ajeetraina/jetson_devicequery:latest\" in 1.000839703s\n  Normal   Pulled     5m29s                  kubelet            Successfully pulled image \"ajeetraina/jetson_devicequery:latest\" in 967.072951ms\n  Normal   Pulled     4m59s                  kubelet            Successfully pulled image \"ajeetraina/jetson_devicequery:latest\" in 1.025604394s\n  Normal   Created    4m59s (x4 over 5m45s)  kubelet            Created container nvidia\n  Normal   Started    4m59s (x4 over 5m45s)  kubelet            Started container nvidia\n  Warning  BackOff    4m20s (x8 over 5m42s)  kubelet            Back-off restarting failed container\n  Normal   Pulling    2m47s (x6 over 7m51s)  kubelet            Pulling image \"ajeetraina/jetson_devicequery:latest\"\n</code></pre> <pre><code>pico@pico2:~/test$ sudo KUBECONFIG=/etc/rancher/k3s/k3s.yaml kubectl apply -f ./pod_deviceQuery_jetson4.yaml\npod/devicequery configured\n</code></pre>"},{"location":"nvidia/docker-on-xavier/","title":"Getting started with Docker on NVIDIA Jetson Xavier AGX","text":""},{"location":"nvidia/docker-on-xavier/#installing-docker","title":"Installing Docker","text":"<p>By default, the latest version of Docker is shipped with the development platform. You can verify it by running the below command:</p> <pre><code>xavier@xavier-desktop:~$ sudo docker version\n[sudo] password for xavier: \nClient: Docker Engine - Community\n Version:           20.10.8\n API version:       1.41\n Go version:        go1.16.6\n Git commit:        3967b7d\n Built:             Fri Jul 30 19:54:37 2021\n OS/Arch:           linux/arm64\n Context:           default\n Experimental:      true\n\nServer: Docker Engine - Community\n Engine:\n  Version:          20.10.8\n  API version:      1.41 (minimum version 1.12)\n  Go version:       go1.16.6\n  Git commit:       75249d8\n  Built:            Fri Jul 30 19:52:46 2021\n  OS/Arch:          linux/arm64\n  Experimental:     false\n containerd:\n  Version:          1.4.9\n  GitCommit:        e25210fe30a0a703442421b0f60afac609f950a3\n runc:\n  Version:          1.0.1\n  GitCommit:        v1.0.1-0-g4144b63\n docker-init:\n  Version:          0.19.0\n  GitCommit:        de40ad0\nxavier@xavier-desktop:~$ \n</code></pre>"},{"location":"nvidia/docker-on-xavier/#identify-the-jetson-board","title":"Identify the Jetson board","text":""},{"location":"nvidia/docker-on-xavier/#clone-the-repository","title":"Clone the repository","text":"<pre><code>git clone https://github.com/jetsonhacks/jetsonUtilities\n</code></pre>"},{"location":"nvidia/docker-on-xavier/#execute-the-python-script","title":"Execute the Python Script:","text":"<pre><code>python3 jetsonInfo.py \nNVIDIA Jetson AGX Xavier [16GB]\n L4T 32.3.1 [ JetPack 4.3 ]\n   Ubuntu 18.04.3 LTS\n   Kernel Version: 4.9.140-tegra\n CUDA NOT_INSTALLED\n   CUDA Architecture: 7.2\n OpenCV version: NOT_INSTALLED\n   OpenCV Cuda: NO\n CUDNN: NOT_INSTALLED\n TensorRT: NOT_INSTALLED\n Vision Works: NOT_INSTALLED\n VPI: NOT_INSTALLED\n Vulcan: 1.1.70\nxavier@xavier-desktop:~/jetsonUtilities$ \n</code></pre>"},{"location":"nvidia/docker-on-xavier/#installing-jtop","title":"Installing Jtop","text":"<p>Lucky You! I have created a Docker Image for Jetson Nano few weeks back that you can leverage on Xavier developer kit too. Check this out:</p> <pre><code>docker run --rm -it --gpus all -v /run/jtop.sock:/run/jtop.sock ajeetraina/jetson-stats-nano jtop\n</code></pre> <p>If you want to keep it simple and new to Docker, no worries. Try to install the Python module and you are all good to go.</p> <pre><code>sudo -H pip install -U jetson-stats\nCollecting jetson-stats\n  Downloading https://files.pythonhosted.org/packages/70/57/ce1aec95dd442d94c3bd47fcda77d16a3cf55850fa073ce8c3d6d162ae0b/jetson-stats-3.1.1.tar.gz (85kB)\n    100% |\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588\u2588| 92kB 623kB/s \nBuilding wheels for collected packages: jetson-stats\n  Running setup.py bdist_wheel for jetson-stats ... done\n  Stored in directory: /root/.cache/pip/wheels/5e/b0/97/f0f8222e76879bf04b6e8c248154e3bb970e0a2aa6d12388f9\nSuccessfully built jetson-stats\nInstalling collected packages: jetson-stats\nSuccessfully installed jetson-stats-3.1.1\nxavier@xavier-desktop:~/jetsonUtilities$ \n</code></pre> <p>Don\u2019t get surprise if you encounter the below message. Reboot your system and re-run the command:</p> <pre><code>$jtop\nI can't access jetson_stats.service.\nPlease logout or reboot this board.\n</code></pre> <p></p>"},{"location":"nvidia/docker-on-xavier/#using-jtop-to-see-the-gpu-and-cpu-details","title":"Using Jtop to see the GPU and CPU details","text":""},{"location":"nvidia/docker-on-xavier/#displaying-xavier-information","title":"Displaying Xavier Information","text":""},{"location":"nvidia/docker-on-xavier/#displaying-the-xavier-release-info","title":"Displaying the Xavier Release Info","text":"<pre><code>xavier@xavier-desktop:~$ jetson_release -v\n - NVIDIA Jetson AGX Xavier [16GB]\n   * Jetpack 4.3 [L4T 32.3.1]\n   * NV Power Mode: MODE_15W - Type: 2\n   * jetson_stats.service: active\n - Board info:\n   * Type: AGX Xavier [16GB]\n   * SOC Family: tegra194 - ID:25\n   * Module: P2888-0001 - Board: P2822-0000\n   * Code Name: galen\n   * CUDA GPU architecture (ARCH_BIN): 7.2\n   * Serial Number: 1420921055981\n - Libraries:\n   * CUDA: NOT_INSTALLED\n   * cuDNN: NOT_INSTALLED\n   * TensorRT: NOT_INSTALLED\n   * Visionworks: NOT_INSTALLED\n   * OpenCV: NOT_INSTALLED compiled CUDA: NO\n   * VPI: NOT_INSTALLED\n   * Vulkan: 1.1.70\n - jetson-stats:\n   * Version 3.1.1\n   * Works on Python 2.7.17\nxavier@xavier-desktop:~$ \n</code></pre>"},{"location":"nvidia/getting-started/","title":"Getting Started with NVIDIA Jetson Nano","text":""},{"location":"nvidia/getting-started/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Intent</li> <li>Hardware</li> <li>Software</li> <li>Preparing Your Jetson Nano</li> <li>Flashing SD card image</li> <li>Vefifying Docker Binaries</li> </ol>"},{"location":"nvidia/getting-started/#intent","title":"Intent","text":"<p>Everything and anything you want to know about NVIDIA Jetson Nano, Docker &amp; K3s support</p>"},{"location":"nvidia/getting-started/#hardware","title":"Hardware","text":"<ul> <li>Jetson Nano</li> <li>A Camera Module</li> <li>A 5V 4Ampere Charger</li> <li>64GB SD card</li> </ul>"},{"location":"nvidia/getting-started/#software","title":"Software","text":"<ul> <li>Jetson SD card image from https://developer.nvidia.com/embedded/downloads</li> <li>Etcher software installed on your system</li> </ul>"},{"location":"nvidia/getting-started/#preparing-your-jetson-nano","title":"Preparing Your Jetson Nano","text":""},{"location":"nvidia/getting-started/#1-preparing-your-raspberry-pi-flashing-jetson-sd-card-image","title":"1. Preparing Your Raspberry Pi Flashing Jetson SD Card Image","text":"<ul> <li>Unzip the SD card image</li> <li>Insert SD card into your system. </li> <li>Bring up Etcher tool and select the target SD card to which you want to flash the image.</li> </ul> <pre><code>sudo lshw -C system\npico2                       \n    description: Computer\n    product: NVIDIA Jetson Nano Developer Kit\n    serial: 1422919082257\n    width: 64 bits\n    capabilities: smp cp15_barrier setend swp\n</code></pre>"},{"location":"nvidia/getting-started/#cuda-compiler-and-libraries","title":"CUDA Compiler and Libraries","text":"<pre><code>ajeetraina@ajeetraina-desktop:~/meetup$ nvcc --version\n-bash: nvcc: command not found\najeetraina@ajeetraina-desktop:~/meetup$ export PATH=${PATH}:/usr/local/cuda/bin\najeetraina@ajeetraina-desktop:~/meetup$ export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/cuda/lib64\najeetraina@ajeetraina-desktop:~/meetup$ source ~/.bashrc\najeetraina@ajeetraina-desktop:~/meetup$ nvcc --version\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2019 NVIDIA Corporation\nBuilt on Wed_Oct_23_21:14:42_PDT_2019\nCuda compilation tools, release 10.2, V10.2.89\n</code></pre>"},{"location":"nvidia/getting-started/#devicequery","title":"DeviceQuery","text":"<pre><code>$ pwd\n\n/usr/local/cuda/samples/1_Utilities/deviceQuery\nsudo make\n</code></pre> <pre><code>ajeetraina@ajeetraina-desktop:/usr/local/cuda/samples/1_Utilities/deviceQuery$ sudo make\n/usr/local/cuda-10.2/bin/nvcc -ccbin g++ -I../../common/inc  -m64    -gencode arch=compute_30,code=sm_30 -gencode arch=compute_32,code=sm_32 -gencode arch=compute_53,code=sm_53 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_62,code=sm_62 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_72,code=sm_72 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_75,code=compute_75 -o deviceQuery.o -c deviceQuery.cpp\n/usr/local/cuda-10.2/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_30,code=sm_30 -gencode arch=compute_32,code=sm_32 -gencode arch=compute_53,code=sm_53 -gencode arch=compute_61,code=sm_61 -gencode arch=compute_62,code=sm_62 -gencode arch=compute_70,code=sm_70 -gencode arch=compute_72,code=sm_72 -gencode arch=compute_75,code=sm_75 -gencode arch=compute_75,code=compute_75 -o deviceQuery deviceQuery.o\nmkdir -p ../../bin/aarch64/linux/release\ncp deviceQuery ../../bin/aarch64/linux/release\najeetraina@ajeetraina-desktop:/usr/local/cuda/samples/1_Utilities/deviceQuery$ ls\nMakefile  NsightEclipse.xml  deviceQuery  deviceQuery.cpp  deviceQuery.o  readme.txt\najeetraina@ajeetraina-desktop:/usr/local/cuda/samples/1_Utilities/deviceQuery$ ./deviceQuery\n./deviceQuery Starting...\n\n CUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"NVIDIA Tegra X1\"\n  CUDA Driver Version / Runtime Version          10.2 / 10.2\n  CUDA Capability Major/Minor version number:    5.3\n  Total amount of global memory:                 3956 MBytes (4148387840 bytes)\n  ( 1) Multiprocessors, (128) CUDA Cores/MP:     128 CUDA Cores\n  GPU Max Clock rate:                            922 MHz (0.92 GHz)\n  Memory Clock rate:                             13 Mhz\n  Memory Bus Width:                              64-bit\n  L2 Cache Size:                                 262144 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 32768\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            Yes\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device supports Compute Preemption:            No\n  Supports Cooperative Kernel Launch:            No\n  Supports MultiDevice Co-op Kernel Launch:      No\n  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 0\n  Compute Mode:\n     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.2, CUDA Runtime Version = 10.2, NumDevs = 1\nResult = PASS\n</code></pre>"},{"location":"nvidia/getting-started/#2-verifying-if-it-is-shipped-with-docker-binaries","title":"2. Verifying if it is shipped with Docker Binaries","text":"<pre><code>ajeetraina@ajeetraina-desktop:~$ sudo docker version\n[sudo] password for ajeetraina: \nClient:\n Version:           19.03.6\n API version:       1.40\n Go version:        go1.12.17\n Git commit:        369ce74a3c\n Built:             Fri Feb 28 23:47:53 2020\n OS/Arch:           linux/arm64\n Experimental:      false\n\nServer:\n Engine:\n  Version:          19.03.6\n  API version:      1.40 (minimum version 1.12)\n  Go version:       go1.12.17\n  Git commit:       369ce74a3c\n  Built:            Wed Feb 19 01:06:16 2020\n  OS/Arch:          linux/arm64\n  Experimental:     false\n containerd:\n  Version:          1.3.3-0ubuntu1~18.04.2\n  GitCommit:        \n runc:\n  Version:          spec: 1.0.1-dev\n  GitCommit:        \n docker-init:\n  Version:          0.18.0\n  GitCommit:       \n</code></pre>"},{"location":"nvidia/getting-started/#3-checking-docker-runtime","title":"3. Checking Docker runtime","text":"<p>Starting with JetPack 4.2, NVIDIA has introduced a container runtime with Docker integration. This custom runtime enables Docker containers to access the underlying GPUs available in the Jetson family.</p> <pre><code>pico@pico1:/tmp/docker-build$ sudo nvidia-docker version\nNVIDIA Docker: 2.0.3\nClient:\n Version:           19.03.6\n API version:       1.40\n Go version:        go1.12.17\n Git commit:        369ce74a3c\n Built:             Fri Feb 28 23:47:53 2020\n OS/Arch:           linux/arm64\n Experimental:      false\n\nServer:\n Engine:\n  Version:          19.03.6\n  API version:      1.40 (minimum version 1.12)\n  Go version:       go1.12.17\n  Git commit:       369ce74a3c\n  Built:            Wed Feb 19 01:06:16 2020\n  OS/Arch:          linux/arm64\n  Experimental:     false\n containerd:\n  Version:          1.3.3-0ubuntu1~18.04.2\n  GitCommit:        \n runc:\n  Version:          spec: 1.0.1-dev\n  GitCommit:        \n docker-init:\n  Version:          0.18.0\n  GitCommit:\n</code></pre>"},{"location":"nvidia/getting-started/#installing-docker-compose-on-nvidia-jetson-nano","title":"Installing Docker Compose on NVIDIA Jetson Nano","text":"<p>Jetson Nano doesnt come with Docker Compose installed by default. You will need to install it first:</p> <pre><code>export DOCKER_COMPOSE_VERSION=1.27.4\nsudo apt-get install libhdf5-dev\nsudo apt-get install libssl-dev\nsudo pip3 install docker-compose==\"${DOCKER_COMPOSE_VERSION}\"\napt install python3\napt install python3-pip\npip install docker-compose\n</code></pre> <pre><code>docker-compose version\ndocker-compose version 1.26.2, build unknown\ndocker-py version: 4.3.1\nCPython version: 3.6.9\nOpenSSL version: OpenSSL 1.1.1  11 Sep 2018\n</code></pre> <p>Next, add default runtime for NVIDIA:</p> <p>Edit /etc/docker/daemon.json</p> <pre><code>{\n    \"runtimes\": {\n        \"nvidia\": {\n            \"path\": \"/usr/bin/nvidia-container-runtime\",\n            \"runtimeArgs\": []\n        }\n    },\n\n    \"default-runtime\": \"nvidia\",\n    \"node-generic-resources\": [ \"NVIDIA-GPU=0\" ]\n}\n\n</code></pre> <p>Restart the Docker Daemon</p> <pre><code>systemctl restart docker\n</code></pre>"},{"location":"nvidia/getting-started/#identify-the-jetson-board","title":"Identify the Jetson board","text":"<pre><code>pico@pico1:~$ git clone https://github.com/jetsonhacks/jetsonUtilities\nCloning into 'jetsonUtilities'...\nremote: Enumerating objects: 123, done.\nremote: Counting objects: 100% (39/39), done.\nremote: Compressing objects: 100% (30/30), done.\nremote: Total 123 (delta 15), reused 23 (delta 8), pack-reused 84\nReceiving objects: 100% (123/123), 32.87 KiB | 5.48 MiB/s, done.\nResolving deltas: 100% (49/49), done.\npico@pico1:~$ cd jetson\n-bash: cd: jetson: No such file or directory\npico@pico1:~$ cd jetsonUtilities/\n</code></pre> <pre><code>pico@pico1:~/jetsonUtilities$ ls\nLICENSE  README.md  jetsonInfo.py  scripts\n\npico@pico1:~/jetsonUtilities$ python3 jetsonInfo.py \nNVIDIA Jetson Nano (Developer Kit Version)\n L4T 32.4.4 [ JetPack 4.4.1 ]\n   Ubuntu 18.04.5 LTS\n   Kernel Version: 4.9.140-tegra\n CUDA 10.2.89\n   CUDA Architecture: 5.3\n OpenCV version: 4.1.1\n   OpenCV Cuda: NO\n CUDNN: 8.0.0.180\n TensorRT: 7.1.3.0\n Vision Works: 1.6.0.501\n VPI: 4.4.1-b50\n Vulcan: 1.2.70\n</code></pre>"},{"location":"nvidia/getting-started/#install-the-latest-version-of-cuda","title":"Install the latest version of CUDA","text":"<pre><code>wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/sbsa/cuda-ubuntu1804.pin\nsudo mv cuda-ubuntu1804.pin /etc/apt/preferences.d/cuda-repository-pin-600\nwget https://developer.download.nvidia.com/compute/cuda/11.3.1/local_installers/cuda-repo-ubuntu1804-11-3-local_11.3.1-465.19.01-1_arm64.deb\nsudo dpkg -i cuda-repo-ubuntu1804-11-3-local_11.3.1-465.19.01-1_arm64.deb\nsudo apt-key add /var/cuda-repo-ubuntu1804-11-3-local/7fa2af80.pub\nsudo apt-get update\nsudo apt-get -y install cuda\n</code></pre>"},{"location":"nvidia/getting-started/#verify-docker-runtime","title":"Verify Docker runtime","text":"<pre><code>docker info | grep runtime\n Runtimes: nvidia runc io.containerd.runc.v2 io.containerd.runtime.v1.linux\n</code></pre>"},{"location":"nvidia/getting-started/#testing-gpu-support","title":"Testing GPU Support","text":"<p>We\u2019ll use the deviceQuery NVIDIA test application (included in L4T) to check that we can access the GPU in the cluster. First, we\u2019ll create a Docker image with the appropriate software, run it directly as Docker, then run it using containerd ctr and finally on the Kubernetes cluster itself.</p>"},{"location":"nvidia/getting-started/#running-devicequery-on-docker-with-gpu-support","title":"Running deviceQuery on Docker with GPU support","text":""},{"location":"nvidia/getting-started/#create-a-directory","title":"Create a directory","text":"<pre><code>mkdir test\ncd test\n</code></pre>"},{"location":"nvidia/getting-started/#copy-the-sample-files","title":"Copy the sample files","text":"<p>Copy the demos where deviceQuery is located to the working directory where the Docker image will be created:</p> <pre><code>cp -R /usr/local/cuda/samples .\n</code></pre>"},{"location":"nvidia/getting-started/#create-a-dockerfile","title":"Create a Dockerfile","text":"<pre><code>FROM nvcr.io/nvidia/l4t-base:r32.5.0\nRUN apt-get update &amp;&amp; apt-get install -y --no-install-recommends make g++\nCOPY ./samples /tmp/samples\nWORKDIR /tmp/samples/1_Utilities/deviceQuery\nRUN make clean &amp;&amp; make\nCMD [\"./deviceQuery\"]\n</code></pre> <pre><code>sudo docker build -t ajeetraina/jetson_devicequery . -f Dockerfile\n</code></pre> <pre><code>pico@pico2:~/test$ sudo docker run --rm --runtime nvidia ajeetraina/jetson_devicequery:latest\n./deviceQuery Starting...\n\n CUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"NVIDIA Tegra X1\"\n  CUDA Driver Version / Runtime Version          10.2 / 10.2\n  CUDA Capability Major/Minor version number:    5.3\n  Total amount of global memory:                 3963 MBytes (4155383808 bytes)\n  ( 1) Multiprocessors, (128) CUDA Cores/MP:     128 CUDA Cores\n  GPU Max Clock rate:                            922 MHz (0.92 GHz)\n  Memory Clock rate:                             13 Mhz\n  Memory Bus Width:                              64-bit\n  L2 Cache Size:                                 262144 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 32768\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            Yes\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device supports Compute Preemption:            No\n  Supports Cooperative Kernel Launch:            No\n  Supports MultiDevice Co-op Kernel Launch:      No\n  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 0\n  Compute Mode:\n     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.2, CUDA Runtime Version = 10.2, NumDevs = 1\nResult = PASS\n</code></pre> <p>Test 2: Running deviceQuery on containerd with GPU support</p> <p>Since K3s uses containerd as its runtime by default, we will use the ctr command line to test and deploy the deviceQuery image we pushed on containerd with this script:</p> <pre><code>#!/bin/bash\nIMAGE=ajeetraina/jetson_devicequery:latest\nexport KUBECONFIG=/etc/rancher/k3s/k3s.yaml\nctr i pull docker.io/${IMAGE}\nctr run --rm --gpus 0 --tty docker.io/${IMAGE} deviceQuery\n</code></pre>"},{"location":"nvidia/getting-started/#execute-the-script","title":"Execute the script","text":"<pre><code>sudo sh usectr.sh\n</code></pre> <pre><code>sudo sh usectr.sh \ndocker.io/ajeetraina/jetson_devicequery:latest:                                   resolved       |++++++++++++++++++++++++++++++++++++++| \nmanifest-sha256:dfeaad4046f78871d3852e5d5fb8fa848038c57c34c6554c6c97a00ba120d550: done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:4438ebff930fb27930d802553e13457783ca8a597e917c030aea07f8ff6645c0:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:b1cdeb9e69c95684d703cf96688ed2b333a235d5b33f0843663ff15f62576bd4:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:bf60857fb4964a3e3ce57a900bbe47cd1683587d6c89ecbce4af63f98df600aa:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:0aac5305d11a81f47ed76d9663a8d80d2963b61c643acfce0515f0be56f5e301:    done           |++++++++++++++++++++++++++++++++++++++| \nconfig-sha256:37987db6d6570035e25e713f41e665a6d471d25056bb56b4310ed1cb1d79a100:   done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:f0f57d03cad8f8d69b1addf90907b031ccb253b5a9fc5a11db83c51aa311cbfb:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:08c23323368d4fde5347276d543c500e1ff9b712024ca3f85172018e9440d8b0:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:04da93b342eb651d6b94c74a934a3290697573a907fa0a06067b538095601745:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:f84ceb6e8887e9b3b454813459ee97c2b9730869dbd37d4cca4051958b7a5a36:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:93752947af53e2a3225e145b359b956df36e20521b5dde0fe6d3fb92fd2a9538:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:b235194751dee33624fc154603f7e25ecdfbb02538fb7d55fa796df9afa95fee:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:905b1329c1d473c79650e33b882d980b3522fb72e58ecd3456c4fb3c4039fe92:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:8931d5ba88b488c949f77f990e8f9198b153ceb71afd0369eac9c39beb38f2d6:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:cfb2938be99fb944fe31165bdf44532a5536865ce53b12eb7758d1e2a51ad33e:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:606a67bb8db9a1111022bdc6406442e11c1a66653136c5c777114bf67b61038a:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:2f37138d1c8ac71d9314a0f8996ba69579bbc6ee6a57440557bc7eef486ed292:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:9ce7ce1da17c2b8149573d1d73132f61a73083f0cd498eeb7a0da404fd77db14:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:a36863a728ec9221c83c745f40511946dfd63beca0f10c9afcc774ef7a98e420:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:86dd6e5994e2c15f2783d8d543327479ccee7f3b20023dd962fdb9a211071e16:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:f5299db1221c515de91f59d84b79f2f839f9c94a5d0cc7fad04134e23ec9b88a:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:15a5811e1a7bf377cbac066b04e0b36b4c1a41ca63eb3c67c17b734577f6beea:    done           |++++++++++++++++++++++++++++++++++++++| \nlayer-sha256:cb893097de39451407d7167b312ec56eaea80baa041877af8239dbe833fa044b:    done           |++++++++++++++++++++++++++++++++++++++| \nelapsed: 81.4s                                                                    total:  305.5  (3.8 MiB/s)                                       \nunpacking linux/arm64/v8 sha256:dfeaad4046f78871d3852e5d5fb8fa848038c57c34c6554c6c97a00ba120d550...\n\ndone\n\n./deviceQuery Starting...\n\n CUDA Device Query (Runtime API) version (CUDART static linking)\n\nDetected 1 CUDA Capable device(s)\n\nDevice 0: \"NVIDIA Tegra X1\"\n  CUDA Driver Version / Runtime Version          10.2 / 10.2\n  CUDA Capability Major/Minor version number:    5.3\n  Total amount of global memory:                 3963 MBytes (4155383808 bytes)\n  ( 1) Multiprocessors, (128) CUDA Cores/MP:     128 CUDA Cores\n  GPU Max Clock rate:                            922 MHz (0.92 GHz)\n  Memory Clock rate:                             13 Mhz\n  Memory Bus Width:                              64-bit\n  L2 Cache Size:                                 262144 bytes\n  Maximum Texture Dimension Size (x,y,z)         1D=(65536), 2D=(65536, 65536), 3D=(4096, 4096, 4096)\n  Maximum Layered 1D Texture Size, (num) layers  1D=(16384), 2048 layers\n  Maximum Layered 2D Texture Size, (num) layers  2D=(16384, 16384), 2048 layers\n  Total amount of constant memory:               65536 bytes\n  Total amount of shared memory per block:       49152 bytes\n  Total number of registers available per block: 32768\n  Warp size:                                     32\n  Maximum number of threads per multiprocessor:  2048\n  Maximum number of threads per block:           1024\n  Max dimension size of a thread block (x,y,z): (1024, 1024, 64)\n  Max dimension size of a grid size    (x,y,z): (2147483647, 65535, 65535)\n  Maximum memory pitch:                          2147483647 bytes\n  Texture alignment:                             512 bytes\n  Concurrent copy and kernel execution:          Yes with 1 copy engine(s)\n  Run time limit on kernels:                     Yes\n  Integrated GPU sharing Host Memory:            Yes\n  Support host page-locked memory mapping:       Yes\n  Alignment requirement for Surfaces:            Yes\n  Device has ECC support:                        Disabled\n  Device supports Unified Addressing (UVA):      Yes\n  Device supports Compute Preemption:            No\n  Supports Cooperative Kernel Launch:            No\n  Supports MultiDevice Co-op Kernel Launch:      No\n  Device PCI Domain ID / Bus ID / location ID:   0 / 0 / 0\n  Compute Mode:\n     &lt; Default (multiple host threads can use ::cudaSetDevice() with device simultaneously) &gt;\n\ndeviceQuery, CUDA Driver = CUDART, CUDA Driver Version = 10.2, CUDA Runtime Version = 10.2, NumDevs = 1\nResult = PASS\n\n\n</code></pre>"},{"location":"nvidia/getting-started/#test-3-running-devicequery-on-the-k3s-cluster","title":"Test 3: Running deviceQuery on the K3s cluster","text":"<pre><code>pico@pico2:~/test$ cat pod_deviceQuery.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: devicequery\nspec:\n  containers:\n    - name: nvidia\n      image: ajeetraina/jetson_devicequery:latest\n\n      command: [ \"./deviceQuery\" ]\npico@pico2:~/test$\n</code></pre> <pre><code>sudo KUBECONFIG=/etc/rancher/k3s/k3s.yaml kubectl apply -f ./pod_deviceQuery.yaml\npod/devicequery created\n</code></pre> <pre><code>pico@pico2:~/test$ sudo KUBECONFIG=/etc/rancher/k3s/k3s.yaml kubectl describe pod devicequery\nName:         devicequery\nNamespace:    default\nPriority:     0\nNode:         pico4/192.168.1.163\nStart Time:   Sun, 13 Jun 2021 09:16:44 -0700\nLabels:       &lt;none&gt;\nAnnotations:  &lt;none&gt;\nStatus:       Pending\nIP:           \nIPs:          &lt;none&gt;\nContainers:\n  nvidia:\n    Container ID:  \n    Image:         ajeetraina/jetson_devicequery:latest\n    Image ID:      \n    Port:          &lt;none&gt;\n    Host Port:     &lt;none&gt;\n    Command:\n      ./deviceQuery\n    State:          Waiting\n      Reason:       ContainerCreating\n    Ready:          False\n    Restart Count:  0\n    Environment:    &lt;none&gt;\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-mcrmv (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             False \n  ContainersReady   False \n  PodScheduled      True \nVolumes:\n  kube-api-access-mcrmv:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       &lt;nil&gt;\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              &lt;none&gt;\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type    Reason     Age   From               Message\n  ----    ------     ----  ----               -------\n  Normal  Scheduled  78s   default-scheduler  Successfully assigned default/devicequery to pico4\n  Normal  Pulling    77s   kubelet            Pulling image \"ajeetraina/jetson_devicequery:latest\"\npico@pico2:~/test$\n</code></pre> <pre><code>cat pod_deviceQuery_jetson4.yaml \napiVersion: v1\nkind: Pod\nmetadata:\n  name: devicequery\nspec:\n  nodeName: pico4\n  containers:\n    - name: nvidia\n      image: ajeetraina/jetson_devicequery:latest\n      command: [ \"./deviceQuery\" ]\npico@pico2:~/test$ \n</code></pre> <pre><code>pico@pico2:~/test$ sudo KUBECONFIG=/etc/rancher/k3s/k3s.yaml kubectl describe pod devicequery\nName:         devicequery\nNamespace:    default\nPriority:     0\nNode:         pico4/192.168.1.163\nStart Time:   Sun, 13 Jun 2021 09:16:44 -0700\nLabels:       &lt;none&gt;\nAnnotations:  &lt;none&gt;\nStatus:       Running\nIP:           10.42.1.3\nIPs:\n  IP:  10.42.1.3\nContainers:\n  nvidia:\n    Container ID:  containerd://fd502d6bfa55e2f80b2d50bc262e6d6543fd8d09e9708bb78ecec0b2e09621c3\n    Image:         ajeetraina/jetson_devicequery:latest\n    Image ID:      docker.io/ajeetraina/jetson_devicequery@sha256:dfeaad4046f78871d3852e5d5fb8fa848038c57c34c6554c6c97a00ba120d550\n    Port:          &lt;none&gt;\n    Host Port:     &lt;none&gt;\n    Command:\n      ./deviceQuery\n    State:          Waiting\n      Reason:       CrashLoopBackOff\n    Last State:     Terminated\n      Reason:       Error\n      Exit Code:    1\n      Started:      Sun, 13 Jun 2021 09:21:50 -0700\n      Finished:     Sun, 13 Jun 2021 09:21:50 -0700\n    Ready:          False\n    Restart Count:  5\n    Environment:    &lt;none&gt;\n    Mounts:\n      /var/run/secrets/kubernetes.io/serviceaccount from kube-api-access-mcrmv (ro)\nConditions:\n  Type              Status\n  Initialized       True \n  Ready             False \n  ContainersReady   False \n  PodScheduled      True \nVolumes:\n  kube-api-access-mcrmv:\n    Type:                    Projected (a volume that contains injected data from multiple sources)\n    TokenExpirationSeconds:  3607\n    ConfigMapName:           kube-root-ca.crt\n    ConfigMapOptional:       &lt;nil&gt;\n    DownwardAPI:             true\nQoS Class:                   BestEffort\nNode-Selectors:              &lt;none&gt;\nTolerations:                 node.kubernetes.io/not-ready:NoExecute op=Exists for 300s\n                             node.kubernetes.io/unreachable:NoExecute op=Exists for 300s\nEvents:\n  Type     Reason     Age                    From               Message\n  ----     ------     ----                   ----               -------\n  Normal   Scheduled  7m51s                  default-scheduler  Successfully assigned default/devicequery to pico4\n  Normal   Pulled     5m45s                  kubelet            Successfully pulled image \"ajeetraina/jetson_devicequery:latest\" in 2m5.699757621s\n  Normal   Pulled     5m43s                  kubelet            Successfully pulled image \"ajeetraina/jetson_devicequery:latest\" in 1.000839703s\n  Normal   Pulled     5m29s                  kubelet            Successfully pulled image \"ajeetraina/jetson_devicequery:latest\" in 967.072951ms\n  Normal   Pulled     4m59s                  kubelet            Successfully pulled image \"ajeetraina/jetson_devicequery:latest\" in 1.025604394s\n  Normal   Created    4m59s (x4 over 5m45s)  kubelet            Created container nvidia\n  Normal   Started    4m59s (x4 over 5m45s)  kubelet            Started container nvidia\n  Warning  BackOff    4m20s (x8 over 5m42s)  kubelet            Back-off restarting failed container\n  Normal   Pulling    2m47s (x6 over 7m51s)  kubelet            Pulling image \"ajeetraina/jetson_devicequery:latest\"\n</code></pre> <pre><code>pico@pico2:~/test$ sudo KUBECONFIG=/etc/rancher/k3s/k3s.yaml kubectl apply -f ./pod_deviceQuery_jetson4.yaml\npod/devicequery configured\n</code></pre>"},{"location":"nvidia/jetson-xavier/","title":"Getting Started","text":""},{"location":"nvidia/jetson-xavier/#getting-started-with-jetson-xavier-agx","title":"Getting Started with Jetson Xavier AGX","text":"<p>If you\u2019re an IoT Edge developer and looking out to build and deploy the production-grade end-to-end AI robotics applications, then check out a highly powerful and robust NVIDIA Jetson AGX Xavier developer platform. The NVIDIA\u00ae Jetson AGX Xavier\u2122 Developer Kit provides a full-featured development platform designed for IoT Edge developers to easily create and deploy end-to-end AI robotics applications. This development platform is supported by NVIDIA JetPack and DeepStream SDKs, as well as CUDA\u00ae, cuDNN, and TensorRT software libraries.</p> <p>Referring to AGX rightly as \u201cAutonomous Machines Accelerator Technology\u201d in loose term, the developer kit provides you with all the necessary tools you need to get started right away. And because it\u2019s powered by the new NVIDIA Xavier processor, you now have more than 20X the performance and 10X the energy efficiency of its predecessor, the NVIDIA Jetson TX2.</p> <p>At just 100 x 87 mm, Jetson AGX Xavier offers big workstation performance at 1/10 the size of a workstation. This makes it ideal for autonomous machines like delivery and logistics robots, factory systems, and large industrial UAVs. NVIDIA\u00ae Jetson\u2122 brings accelerated AI performance to the Edge in a power-efficient and compact form factor. Together with NVIDIA JetPack\u2122 SDK, these Jetson modules open the door for you to develop and deploy innovative products across all industries.</p>"},{"location":"nvidia/jetson-xavier/#top-5-compelling-features-of-agx-xavier-kit","title":"Top 5 Compelling Features of AGX Xavier Kit","text":"<ul> <li>Unlike NVIDIA Jetson Nano 2GB/4GB, NVIDIA Jetson AGX Xavier comes with inbuilt 32GB eMMC 5.1 storage. So, that means you really don\u2019t need to buy separate SD card to install/run the operating system. Hence, saving your time to start with the developer kit flawlessly.</li> <li>Compared to NVIDIA Jetson Nano, the new Jetson AGX Xavier module makes AI-powered autonomous machines possible, running in as little as 10W and delivering up to 32 TOPs.</li> <li>AGX Xavier support up-to 6 cameras (36 via virtual channels). Cool, isn\u2019t it?</li> <li>AGX Xavier comes with inbuilt 32 GB 256-bit LPDDR4x 136.5GB/s memory, much powerful to run applications like DeepStreaming.</li> <li>Check out production-ready products based on Jetson AGX Xavier available from Jetson ecosystem partners.</li> </ul> <p>Jetson AGX Xavier module with thermal solution:</p> <ul> <li>Reference carrier board</li> <li>65W power supply with AC cord</li> <li>Type C to Type A cable (USB 3.1 Gen2)</li> <li>Type C to Type A adapter (USB 3.1 Gen 1)</li> </ul>"},{"location":"nvidia/jetson-xavier/#comparing-jetson-nano-vs-jetson-agx-xavier","title":"Comparing Jetson Nano Vs Jetson AGX Xavier","text":""},{"location":"nvidia/oled-groove-jetson/","title":"OLED Display using Groove Hat on Jetson Nano","text":"<p>Grove Shield for Jetson Nano is an expansion board for Jetson Nano, designed by Seeed Studio, for the orderliness of your connected sensors when you develop projects with Pi. It maintains 24-Pin GPIO and provides 15 additional Grove ports based on the MM32 chip, along with other interfaces, giving you a great and quick development experience.</p>"},{"location":"nvidia/oled-groove-jetson/#feature","title":"Feature","text":"<ul> <li>Grove &amp; GPIO Pi Hat for Raspberry Pi Series: Break out all the pins and power of the Raspberry Pi to provide 15 multi-function. Grove ports and compatible 24-Pin GPIO based on a 12-bit ADC MM32 chip</li> <li>Rich Peripherals for Grove: Provide 15 Grove ports including 3\u00d7 I2C, 1\u00d7 UART, 6\u00d7 Digital, and 4\u00d7 Analog, which also contains 1x PWM port, and the SWD Debug interface.</li> <li>Plug and Play: Benefit from convenient Grove connectors that supports more than 60 Grove modules</li> </ul>"},{"location":"nvidia/oled-groove-jetson/#getting-started","title":"Getting Started","text":""},{"location":"nvidia/oled-groove-jetson/#step-1-plug-the-grove-base-hat-into-jetson-nano","title":"Step 1. Plug the Grove Base Hat into Jetson Nano","text":""},{"location":"nvidia/oled-groove-jetson/#step-2-connect-oled","title":"Step 2. Connect OLED","text":""},{"location":"nvidia/oled-groove-jetson/#step-3-installation","title":"Step 3. Installation","text":"<pre><code>curl -sL https://github.com/Seeed-Studio/grove.py/raw/master/install.sh | sudo bash -s -\n</code></pre> <p>if everything goes well, you will see the following notice.</p> <pre><code>...\n...\n#######################################################\n  Lastest Grove.py from github install complete   !!!!!\n#######################################################\n</code></pre> <p>If you use the I2C tool to scan the I2C address of the grove module, you may find two or more address. 0x04 is the adrress of the Grove Base Hat for Raspberry Pi.</p>"},{"location":"nvidia/oled-groove-jetson/#step-4-using-i2cdetect-command","title":"Step 4. Using i2cdetect command","text":"<pre><code> i2cdetect -r -y 1\n     0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f\n00:          -- -- -- -- -- 08 -- -- -- -- -- -- -- \n10: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n30: -- -- -- -- -- -- -- -- -- -- -- -- 3c -- -- -- \n40: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n50: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n60: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n70: -- -- -- -- -- -- 76 --                  \n</code></pre> <p>This is the output of the i2cdetect command, which is used to scan for I2C (Inter-Integrated Circuit) devices connected to a system. The command lists the I2C device addresses found on bus 1 (-y 1).</p> <p>The first row represents the I2C addresses in hexadecimal form (0x00 to 0x7F). The following rows indicate the presence of an I2C device at the corresponding address by showing a two-digit hexadecimal number. An empty cell (--) means that there is no device at the corresponding address.</p> <p>Based on the output, there are two I2C devices detected at addresses 0x3c and 0x76. The address 0x3c might correspond to a display controller or a sensor, while the address 0x76 might correspond to a barometer or a temperature sensor.</p> <p>It is important to note that this output only indicates the presence of the I2C devices and not their functionality. Further testing and analysis are required to determine if the devices are working correctly.</p>"},{"location":"nvidia/oled-groove-jetson/#step-5-running-the-python-script","title":"Step 5. Running the Python Script","text":"<pre><code>git clone https://github.com/Seeed-Studio/grove.py\ncd grove.py/grove\n</code></pre> <pre><code>#!/bin/bash\n#\n: &lt;&lt;'EOF'\nThe MIT License (MIT)\n\nSeeed-Studio Raspberry Pi Hats.\n  Peter Yang, turmary@126.com\nCopyright (C) 2018 Seeed Technology Co.,Ltd.\nEOF\n\n\n_DEBUG=0\n\n_install_extra_library=true\n\n_package_name=grove.py\n_seeed_source_list=/etc/apt/sources.list.d/seeed.list\n_seeed_apt_key=\"BB8F 40F3\"\n_repo_package_url=https://github.com/Seeed-Studio/$_package_name/archive/master.zip\n\nBLACKLIST=/etc/modprobe.d/raspi-blacklist.conf\nCONFIG=/boot/config.txt\nif [ $_DEBUG -ne 0 ]; then\n    BLACKLIST=./raspi-blacklist.conf\n    CONFIG=./config.txt\nfi\n\n\nset_config_var() {\n    lua - \"$1\" \"$2\" \"$3\" &lt;&lt;EOF &gt; \"$3.bak\"\nlocal key=assert(arg[1])\nlocal value=assert(arg[2])\nlocal fn=assert(arg[3])\nlocal file=assert(io.open(fn))\nlocal made_change=false\nfor line in file:lines() do\n    if line:match(\"^#?%s*\"..key..\"=.*$\") then\n        line=key..\"=\"..value\n        made_change=true\n    end\n    print(line)\nend\n\nif not made_change then\n    print(key..\"=\"..value)\nend\nEOF\n\n    mv \"$3.bak\" \"$3\"\n}\n\nget_i2c() {\n    egrep -q \"^(device_tree_param|dtparam)=([^,]*,)*i2c(_arm)?(=(on|true|yes|1))?(,.*)?$\" $CONFIG\n    echo $?\n}\n\ndo_i2c() {\n    DEFAULT=--defaultno\n    if [ $(get_i2c) -eq 0 ]; then\n        DEFAULT=\n    fi\n    RET=$1\n    if [ $RET -eq 0 ]; then\n        SETTING=on\n        STATUS=enabled\n    elif [ $RET -eq 1 ]; then\n        SETTING=off\n        STATUS=disabled\n    else\n        return $RET\n    fi\n\n    set_config_var dtparam=i2c_arm $SETTING $CONFIG &amp;&amp;\n    if ! [ -e $BLACKLIST ]; then\n        touch $BLACKLIST\n    fi\n    sed $BLACKLIST -i -e \"s/^\\(blacklist[[:space:]]*i2c[-_]bcm2708\\)/#\\1/\"\n    sed /etc/modules -i -e \"s/^#[[:space:]]*\\(i2c[-_]dev\\)/\\1/\"\n    if ! grep -q \"^i2c[-_]dev\" /etc/modules; then\n        printf \"i2c-dev\\n\" &gt;&gt; /etc/modules\n    fi\n    dtparam i2c_arm=$SETTING\n    modprobe i2c-dev\n}\n\nfunction apt_install() {\n    pkg_name=$1\n\n    for ((i = 0; i &lt; 3; i++)); {\n        apt-get install -y $pkg_name\n        pkg_status=$(dpkg -s $pkg_name | egrep \"Status:.*\" | awk '{ printf \"%s\", $2; }')\n        [ \"$pkg_status\" == \"install\" ] &amp;&amp; return 0\n    }\n    return 1\n}\n\nalias  pip=' pip --no-cache-dir'\nalias pip3='pip3 --no-cache-dir'\n\nfunction pip_install() {\n    local fields\n    pkg_name=$1\n    pip_cmd=${2}\n\n    fields=( $pip_cmd )\n    for ((i = 0; i &lt; 3; i++)); {\n        $pip_cmd\n        pkg_status=$(${fields[0]} list --format=columns | egrep \"$pkg_name \" | awk '{ printf \"%s\", $1; }')\n        [ \"$pkg_status\" == \"$pkg_name\" ] &amp;&amp; return 0\n    }\n    return 1\n}\n\nfunction platform_get() {\n    local dts_model platform\n\n    dts_model=$(strings /proc/device-tree/model)\n\n    case \"$dts_model\" in\n    TI\\ AM335x*)\n        platform=bbb;;\n    Raspberry\\ Pi*)\n        platform=rpi;;\n    Freescale\\ i\\.MX8MQ\\ Phanbell)\n        platform=coral;;\n    NVIDIA\\ Jetson\\ Nano*)\n        platform=jetson_nano;;\n    *)\n        platform=\"unknown\";;\n    esac\n    echo $platform\n}\n\n\n\n# Get platform type\nplatform=$(platform_get)\n\nif [[ \"$platform\" == \"jetson_nano\" ]];then\n    _install_extra_library=false\nfi  \n\ndo_uninstall=false\nif [ \"$1\" == \"uninstall\" ]; then\n    do_uninstall=true\nfi\n\n# Everything else needs to be run as root\nif [ $(id -u) -ne 0 ]; then\n    printf \"Script must be run as root. Try 'sudo $0'\\n\"\n    exit 1\nfi\n\n### Uninstall this package ###\nif [ \"$do_uninstall\" == \"true\" ]; then\n    # To remove all users installaon\n    pip  uninstall -y $_package_name\n    pip3 uninstall -y $_package_name\n    apt-get -y remove python-grove-py\n    apt-get -y remove python3-grove-py\n    exit 0\nfi\n\n# install dependencies\n### add repository\nif [ ! -f $_seeed_source_list ]; then\n    case \"$platform\" in\n    coral)\n        code_name=\"mendel-beaker\";;\n    rpi)\n        code_name=\"stretch\";;\n    jetson_nano)\n        code_name=\"bionic\";;\n    *)\n        code_name=\"unknown\";;\n    esac\n    echo \"deb https://seeed-studio.github.io/pi_repo/ $code_name main\" | tee $_seeed_source_list\nfi\n\n### add public GPG key\nif ! apt-key list | egrep \"$_seeed_apt_key\" &gt; /dev/null; then\n    curl https://seeed-studio.github.io/pi_repo/public.key | apt-key add -\nfi\n\n\n\n## Initial installation\nr=0\n\n## Update apt source\napt -y update\n\ncase \"$platform\" in\ncoral)\n    apt_install python-pip\n    apt_install python3-pip\n    apt_install python-setuptools\n    apt_install python3-setuptools\n    apt_install python-wheel\n    apt_install python3-wheel\n\n    ## install library enum\n    ;;\njetson_nano)\n\n    apt_install python-pip  \n    apt_install python3-pip\n    apt_install python-setuptools\n    apt_install python3-setuptools\n    apt_install python-wheel\n    apt_install python3-wheel\n    pushd .\n    cd `dirname $0`\n    cp ./udev/jetson-nano/99-tegra-i2cset.rules /etc/udev/rules.d/\n    popd    \n    ;;\nrpi)\n    apt_install python-pip  \n    apt_install python3-pip\n\n    ### install I2C ###\n    if [ $(get_i2c) -ne 0 ]; then\n        # enable i2c interface\n        echo Enable I2C interface ...\n        do_i2c 0\n    fi\n    echo I2C interface enabled...\n\n    ## install library raspberry-gpio-python\n    (( r == 0 )) &amp;&amp; { apt_install python-rpi.gpio;  r=$?; }\n    (( r == 0 )) &amp;&amp; { apt_install python3-rpi.gpio; r=$?; }\n    ;;\n\n*)\n    echo \"unsupport platform $platform, abort ...\"\n    exit 1\n    ;;\nesac\n\n## install MRAA &amp; UPM\n### libmraa\n(( r == 0 )) &amp;&amp; { apt_install libmraa1;    r=$?; }\n\n### python2\n(( r == 0 )) &amp;&amp; { apt_install python-mraa; r=$?; }\n(( r == 0 )) &amp;&amp; { apt_install python-upm;  r=$?; }\n\n### python3\n(( r == 0 )) &amp;&amp; { apt_install python3-mraa;r=$?; }\n(( r == 0 )) &amp;&amp; { apt_install python3-upm; r=$?; }\n\n## install library libbma456\nif [[ \"$_install_extra_library\" == \"true\" ]];then\n    (( r == 0 )) &amp;&amp; { apt_install libbma456; r=$?; }\nfi\n\n## install library libbmi088\nif [[ \"$_install_extra_library\" == \"true\" ]];then\n    (( r == 0 )) &amp;&amp; { apt_install libbmi088; r=$?; }\nfi\n\n## install library rpi-ws281x\nif [ \"X$platform\" == \"Xrpi\" ]; then\n    (( r == 0 )) &amp;&amp; { pip_install rpi-ws281x 'pip  install rpi-ws281x'; r=$?; }\n    (( r == 0 )) &amp;&amp; { pip_install rpi-ws281x 'pip3 install rpi-ws281x'; r=$?; }\nfi\n\n## install library smbus\n(( r == 0 )) &amp;&amp; { pip_install smbus  'pip  install smbus'; r=$?; }\n(( r == 0 )) &amp;&amp; { pip_install smbus  'pip3 install smbus'; r=$?; }\n\n## install library smbus2\n(( r == 0 )) &amp;&amp; { pip_install smbus2 'pip  install smbus2'; r=$?; }\n(( r == 0 )) &amp;&amp; { pip_install smbus2 'pip3 install smbus2'; r=$?; }\n\n## install library bme680\n\n(( r == 0 )) &amp;&amp; { pip_install bme680 'pip  install bme680'; r=$?; }\n(( r == 0 )) &amp;&amp; { pip_install bme680 'pip3 install bme680'; r=$?; }\n\n## install library rpi-vl53l0x\nif [[ \"$_install_extra_library\" == \"true\" ]];then\n    (( r == 0 )) &amp;&amp; { pip_install rpi-vl53l0x 'pip  install rpi-vl53l0x'; r=$?; }\n    (( r == 0 )) &amp;&amp; { pip_install rpi-vl53l0x 'pip3 install rpi-vl53l0x'; r=$?; }\nfi\n\n## install library sgp30\n(( r == 0 )) &amp;&amp; { pip_install sgp30 'pip  install sgp30'; r=$?; }\n(( r == 0 )) &amp;&amp; { pip_install sgp30 'pip3 install sgp30'; r=$?; }\n# install this python repository\n(( r == 0 )) &amp;&amp; { pip_install grove.py \"pip  install --upgrade $_repo_package_url\"; r=$?; }\n(( r == 0 )) &amp;&amp; { pip_install grove.py \"pip3 install --upgrade $_repo_package_url\"; r=$?; }\n(( r == 0 )) &amp;&amp; { which grove_button &gt; /dev/null; r=$?; }\n\n(( r != 0 )) &amp;&amp; {\n    echo \"-------------------------------------------------------\"\n    echo \"     Grove.py installation FAILED, FAILED, FAILED      \"\n    echo \"-------------------------------------------------------\"\n    exit 1\n}\n\nsync\nsleep 1\nsync \n\necho \"#######################################################\"\necho \"  Lastest Grove.py from github install complete   !!!!!\"\necho \"#######################################################\"\nexit 0\n</code></pre>"},{"location":"nvidia/oled-groove-jetson/#step-6-executing-the-script","title":"Step 6. Executing the script","text":"<pre><code>python3 grove_oled_display_128x64.py\n</code></pre>"},{"location":"nvidia/oled-groove-jetson/#results","title":"Results:","text":""},{"location":"nvidia/ollama-on-jetson-nano/","title":"Ollama on Jetson Nano","text":"<p>NVIDIA Jetson devices are powerful platforms designed for edge AI applications, offering excellent GPU acceleration capabilities to run compute-intensive tasks like language model inference. </p> <p>With official support for NVIDIA Jetson devices, Ollama brings the ability to manage and serve Large Language Models (LLMs) locally, ensuring privacy, performance, and offline operation. By integrating Open WebUI, you can enhance your workflow with an intuitive web interface for managing these models.</p> <p>This guide will walk you through setting up Ollama on your Jetson device, integrating it with Open WebUI, and configuring the system for optimal GPU utilization. Whether you're a developer or an AI enthusiast, this setup allows you to harness the full potential of LLMs right on your Jetson device.</p>"},{"location":"nvidia/ollama-on-jetson-nano/#pre-requisite","title":"Pre-requisite","text":"<ol> <li>Jetson Nano</li> <li>A 5V 4Ampere Charger</li> <li>64GB SD card</li> <li>WiFi Adapter</li> <li>Wireless Keyboard</li> <li>Wireless mouse</li> </ol>"},{"location":"nvidia/ollama-on-jetson-nano/#software","title":"Software","text":"<ul> <li>Download Jetson SD card image from this link</li> <li>Raspberry Pi Imager installed on your local system</li> </ul>"},{"location":"nvidia/ollama-on-jetson-nano/#preparing-your-jetson-nano","title":"Preparing Your Jetson Nano","text":"<ol> <li>Unzip the SD card image</li> <li>Insert SD card into your system.</li> <li>Bring up Raspberry Pi Imager tool to flash image into the SD card</li> </ol>"},{"location":"nvidia/ollama-on-jetson-nano/#step-0-verify-the-jetson-device","title":"Step 0. Verify the Jetson device","text":"<p>Begin by verifying the L4T (Linux for Tegra) version on your Jetson device. Each Jetson platform runs a specific JetPack version tied to an L4T release. To check your configuration:</p> <pre><code>cat /etc/nv_tegra_release\n# R32 (release), REVISION: 7.1, GCID: 29818004, BOARD: t210ref, EABI: aarch64, DATE: Sat Feb 19 17:05:08 UTC 2022\n</code></pre> <p>This output confirms the device is using L4T R32.7.1, compatible with JetPack 4.6.1. Ensure your Jetson device is updated to the latest supported L4T version to avoid compatibility issues.</p>"},{"location":"nvidia/ollama-on-jetson-nano/#step-1-update-the-apt-repository","title":"Step 1. Update the APT repository","text":"<p>Ensure your system is up to date to avoid errors during the installation of dependencies:</p> <pre><code>sudo apt update\n</code></pre>"},{"location":"nvidia/ollama-on-jetson-nano/#step-2-install-the-curl-package","title":"Step 2. Install the curl package","text":"<p>The Ollama installation script requires curl to fetch and execute:</p> <pre><code>sudo apt install curl\n</code></pre>"},{"location":"nvidia/ollama-on-jetson-nano/#step-3-install-ollama","title":"Step 3. Install Ollama","text":"<p>Install Ollama using its official installation script, which automatically sets up the required services and permissions:</p> <pre><code>curl -fsSL https://ollama.com/install.sh | sh\n</code></pre> <pre><code>&gt;&gt;&gt; Adding ollama user to video group...\n&gt;&gt;&gt; Adding current user to ollama group...\n&gt;&gt;&gt; Creating ollama systemd service...\n&gt;&gt;&gt; Enabling and starting ollama service...\nCreated symlink /etc/systemd/system/default.target.wants/ollama.service \u2192 /etc/systemd/system/ollama.service.\n&gt;&gt;&gt; NVIDIA JetPack ready.\n&gt;&gt;&gt; The Ollama API is now available at 127.0.0.1:11434.\n&gt;&gt;&gt; Install complete. Run \"ollama\" from the command line.\n</code></pre> <p>Ollama is now ready to run locally, leveraging your Jetson\u2019s GPU for efficient LLM inference.</p>"},{"location":"nvidia/ollama-on-jetson-nano/#step-4-explore-the-ollama-cli","title":"Step 4. Explore the  Ollama CLI","text":"<p>Ollama provides a CLI to manage and interact with models. To view available commands:</p> <pre><code>ollama\nUsage:\n  ollama [flags]\n  ollama [command]\n\nAvailable Commands:\n  serve       Start ollama\n  create      Create a model from a Modelfile\n  show        Show information for a model\n  run         Run a model\n  stop        Stop a running model\n  pull        Pull a model from a registry\n  push        Push a model to a registry\n  list        List models\n  ps          List running models\n  cp          Copy a model\n  rm          Remove a model\n  help        Help about any command\n\nFlags:\n  -h, --help      help for ollama\n  -v, --version   Show version information\n\nUse \"ollama [command] --help\" for more information about a command.\n</code></pre>"},{"location":"nvidia/ollama-on-jetson-nano/#step-5-list-available-models","title":"Step 5. List Available Models","text":"<p>Check the preloaded models available in Ollama:</p> <pre><code>$ ollama list\nNAME                     ID              SIZE      MODIFIED\nllama3:latest            365c0bd3c000    4.7 GB    4 weeks ago\ncodellama:latest         8fdf8f752f6e    3.8 GB    4 months ago\ncodellama:7b-instruct    8fdf8f752f6e    3.8 GB    4 months ago\nllama3:8b                365c0bd3c000    4.7 GB    4 months ago\nmistral:latest           61e88e884507    4.1 GB    9 months ago\nllama2:latest            78e26419b446    3.8 GB    10 months ago\n</code></pre>"},{"location":"nvidia/ollama-on-jetson-nano/#step-6-run-a-model","title":"Step 6. Run a model","text":"<p>Run the llama3 model and perform tasks like generating Python code:</p> <pre><code>ollama run llama3\n&gt;&gt;&gt; &gt; Can you write a Python script to calculate the factorial of a number?\nSure! Here\u2019s the code:\n\ndef factorial(n):\n    if n == 0 or n == 1:\n        return 1\n    else:\n        return n * factorial(n - 1)\n\nnum = int(input(\"Enter a number: \"))\nprint(f\"The factorial of {num} is {factorial(num)}\")\n</code></pre>"},{"location":"nvidia/ollama-on-jetson-nano/#integrating-open-webui-with-ollama","title":"Integrating Open WebUI with Ollama","text":"<p>Open WebUI complements Ollama by providing an intuitive web-based interface to manage and interact with LLMs.</p>"},{"location":"nvidia/ollama-on-jetson-nano/#step-1-stop-the-ollama-service","title":"Step 1: Stop the Ollama Service","text":"<p>Before proceeding, stop the system-wide Ollama service to avoid conflicts when running it in Docker:</p> <pre><code>sudo systemctl disable ollama\n</code></pre>"},{"location":"nvidia/ollama-on-jetson-nano/#step-2-run-ollama-with-docker","title":"Step 2. Run Ollama with Docker","text":"<p>Deploy Ollama as a Docker container with GPU support:</p> <pre><code>sudo docker run -d --gpus=all --runtime=nvidia -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama\n\n</code></pre>"},{"location":"nvidia/ollama-on-jetson-nano/#step-3-run-open-webui","title":"Step 3. Run Open WebUI","text":"<p>Run Open WebUI with GPU acceleration in a separate Docker container:</p> <pre><code>sudo docker run -d -p 3000:8080 --gpus all --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:cuda\n</code></pre>"},{"location":"nvidia/ollama-on-jetson-nano/#step-4-verify-running-containers","title":"Step 4. Verify Running Containers","text":"<p>Ensure both Ollama and Open WebUI containers are running correctly:</p> <pre><code>sudo docker ps\nCONTAINER ID   IMAGE                                COMMAND               CREATED          STATUS                            PORTS                                           NAMES\ndee2d1fbe4cf   ghcr.io/open-webui/open-webui:cuda   \"bash start.sh\"       10 seconds ago   Up 6 seconds (health: starting)   0.0.0.0:3000-&gt;8080/tcp, :::3000-&gt;8080/tcp       open-webui\n9fd89a4fa908   ollama/ollama                        \"/bin/ollama serve\"   52 seconds ago   Up 48 seconds                     0.0.0.0:11434-&gt;11434/tcp, :::11434-&gt;11434/tcp   ollama\n</code></pre>"},{"location":"nvidia/ollama-on-jetson-nano/#results","title":"Results:","text":"<pre><code>cuda: Pulling from open-webui/open-webui\n6d29a096dd42: Pull complete\n6fab32a80202: Pull complete\n610eb561c31b: Pull complete\n50c0fb1f456e: Pull complete\nae5672aeb8ae: Pull complete\n4f4fb700ef54: Pull complete\n639718444375: Pull complete\n5dcf97af08b1: Pull complete\nea9079f84622: Pull complete\ne3fc97a4f07a: Pull complete\na538afa31f12: Pull complete\n86ede3d9066a: Pull complete\na5aa461a25d1: Pull complete\n6acc9cdc9b03: Pull complete\n1920af2d5f9d: Pull complete\nDigest: sha256:781acd8f2b45bdf45ac9a89fa80d52a6a966d9e1e7b55fbb5f0f1397ce5d9515\nStatus: Downloaded newer image for ghcr.io/open-webui/open-webui:cuda\n843100c8d64d0ab9ea78fd64f4ffced0a62ce8783c850ce66d7ebb890f102e5a\n</code></pre> <pre><code>ajeetraina@ajeetraina-desktop:~$ sudo docker ps\n[sudo] password for ajeetraina:\nCONTAINER ID   IMAGE                                COMMAND           CREATED         STATUS                     PORTS                                       NAMES\n843100c8d64d   ghcr.io/open-webui/open-webui:cuda   \"bash start.sh\"   4 minutes ago   Up 4 minutes (unhealthy)   0.0.0.0:3000-&gt;8080/tcp, :::3000-&gt;8080/tcp   open-webui\n</code></pre>"},{"location":"nvidia/ollama-on-jetson-nano/#bundled-installation-of-open-webui-with-ollama","title":"Bundled Installation of Open WebUI with Ollama","text":"<p>For a simplified setup, you can use a bundled Docker image that integrates both Open WebUI and Ollama.</p>"},{"location":"nvidia/ollama-on-jetson-nano/#using-gpu","title":"Using GPU","text":"<p>This installation method uses a single container image that bundles Open WebUI with Ollama, allowing for a streamlined setup via a single command. Choose the appropriate command based on your hardware setup:</p> <pre><code>sudo docker run -d -p 3000:8080 --gpus=all -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama\n</code></pre>"},{"location":"nvidia/ollama-on-jetson-nano/#using-cpu-only","title":"Using CPU only","text":"<p>For CPU Only: If you're not using a GPU, use this command instead:</p> <pre><code>sudo docker run -d -p 3000:8080 -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama\n</code></pre> <p>Both commands facilitate a built-in, hassle-free installation of both Open WebUI and Ollama, ensuring that you can get everything up and running swiftly.</p>"},{"location":"nvidia/ollama-on-jetson-nano/#conclusion","title":"Conclusion","text":"<p>Once configured, Open WebUI can be accessed at http://localhost:3000, while Ollama operates at http://localhost:11434. This setup provides a seamless and GPU-accelerated environment for running and managing LLMs locally on NVIDIA Jetson devices.</p> <p>This guide showcases the power and versatility of NVIDIA Jetson devices when paired with Ollama and Open WebUI, enabling advanced AI workloads at the edge with ease and efficiency.</p>"},{"location":"nvidia/redis-grafana-docker/","title":"BME Sensor Analytics using Redis TimeSeries, Grafana and Docker","text":"<p>Imagine you\u2019re an air-conditioner manufacturing company that sells millions of smart AC units to consumers. You are building a centralized, smart climate control system that collects sensor data about a house\u2019s temperature, pressure, and humidity and sends it to a central location for an efficiency analysis to help end users trim their electricity bills.</p> <p>This blog post will show a simplified version of such a use case to demonstrate how it all works\u2014so you can understand how to manage a wide variety of real-time IoT sensor data in Redis. </p> <p>Here\u2019s what we used: </p> <ul> <li>A BME680 environmental sensor to simulate a smart air conditioner and send data to Redis</li> <li>The RedisTimeSeries module to add time-series capabilities to Redis and store the data in time-series format</li> <li>Grafana with Redis Data Source to create graphs for usage analysis</li> </ul>"},{"location":"nvidia/redis-grafana-docker/#hardware-requirements","title":"Hardware requirements:","text":"<ul> <li>Jetson Nano: 2GB Model ($59)</li> <li>A 5V 4Amp charger</li> <li>128GB SD card</li> <li>BME680 sensors</li> </ul>"},{"location":"nvidia/redis-grafana-docker/#software-requirements","title":"Software requirements:","text":"<ul> <li>Jetson SD card image from NVIDIA</li> <li>Etcher software installed on your system Preparing Your Jetson Nano for OS Installation Unzip the SD card image downloaded from  https://developer.nvidia.com/embedded/downloads. Insert the SD card into your system. Bring up the Etcher tool and select the target SD card to which you want to flash the image.</li> </ul> <p>Follow this 10-step process to see how it all fits together:</p>"},{"location":"nvidia/redis-grafana-docker/#step-1-get-your-sensors","title":"Step 1: Get your sensors","text":"<p>There\u2019s a huge variety of sensors on the market, but this demonstration uses a Pimoroni BME680 breakout board. BME680 is an integrated environmental sensor developed for mobile applications and wearables, where size and low power consumption are key requirements. It can measure temperature, pressure, humidity, and indoor air quality, and is Raspberry Pi and Arduino-compatible.</p>"},{"location":"nvidia/redis-grafana-docker/#step-2-set-up-your-iot-board","title":"Step 2: Set up your IoT board","text":"<p>For this demonstration, we\u2019re using an NVIDIA Jetson Nano board, a small, powerful computer for developers to learn, explore, and build AI applications for edge devices. Priced at $59, it\u2019s basically a developer kit that includes a Jetson Nano module with 2GB memory and delivers 472 GFLOPS of compute power. This demonstration should also work with other popular IoT devices, such as the Raspberry Pi, Arduino, Banana Pi, etc.</p>"},{"location":"nvidia/redis-grafana-docker/#step-3-wire-it-up","title":"Step 3: Wire it up","text":"<p>The BME680 plugs directly into a Jetson Nano board without any connecting wires.</p>"},{"location":"nvidia/redis-grafana-docker/#step-4-get-your-sensor-working","title":"Step 4: Get your sensor working","text":"<p>After wiring the sensors, we recommend running I2C detection with i2cdetect to verify that you see the device: in our case it shows 76. Please note that the sensor communicates with a microcontroller using I2C or SPI communication protocols.</p> <pre><code>$ i2cdetect -r -y 1\n     0  1  2  3  4  5  6  7  8  9  a  b  c  d  e  f\n00:          -- -- -- -- -- -- -- -- -- -- -- -- -- \n10: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n20: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n30: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n40: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n50: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n60: -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- -- \n70: -- -- -- -- -- -- 76 --\n</code></pre>"},{"location":"nvidia/redis-grafana-docker/#step-5-get-ready-to-redis","title":"Step 5: Get ready to Redis","text":"<p>You will need a Redis server up and running, either on your local laptop or in the cloud, and the Redis server must be compiled with the RedisTimeSeries module. In this demonstration, we\u2019re using Redis Enterprise Cloud, a fully managed cloud database service that comes with the RedisTimeSeries module already built in and integrated.</p>"},{"location":"nvidia/redis-grafana-docker/#step-6-set-up-redis-enterprise-cloud","title":"Step 6: Set up Redis Enterprise Cloud","text":"<p>If you are completely new to RedisTimeSeries, check out our RedisTimeSeries Quick Start tutorial. It explains how to get started with Redis Enterprise Cloud and how to enable RedisTimeSeries. You will need a few details for this implementation:</p> <ul> <li>Redis database name</li> <li>Redis database endpoint</li> <li>Port number</li> <li>Default user password</li> </ul> <p></p>"},{"location":"nvidia/redis-grafana-docker/#step-7-clone-the-project-repository","title":"Step 7: Clone the project repository","text":"<pre><code>$ git clone https://github.com/redis-developer/redis-datasets\n$ cd redis-datasets/redistimeseries/realtime-sensor-jetson\n</code></pre> <p>Reading the sensor values from the BME680 is fairly straightforward, but requires you to set a few configuration values. You can also run the sensor in two different \u201cmodes\u201d\u2014with or without gas readings. Just taking temperature, pressure, and humidity readings lets you sample data much faster.</p> <p>Let\u2019s look first at the library import and the configuration settings. Open a terminal window, create a file, and then type the following:</p> <pre><code>import bme680\nimport time\nimport datetime\nimport csv\nimport argparse\nimport redis\n</code></pre> <p>The first module, bme680, allows you to easily write Python code that reads the humidity, temperature, and pressure from the sensor. Similarly, there are other Python modules, such as time, to handle time-related tasks, redis to import Redis Python modules, and so on. We\u2019re using the time library to introduce a small delay between each reading of the sensor to help ensure consistent results.</p> <pre><code>print(\"\"\"read-sensor.py - Displays temperature, pressure, humidity, and gas.\nPress Ctrl+C to exit!\n\"\"\")\n\ntry:\n    sensor = bme680.BME680(bme680.I2C_ADDR_PRIMARY)\nexcept IOError:\n    sensor = bme680.BME680(bme680.I2C_ADDR_SECONDARY)\n\n# These calibration data can safely be commented\n# out, if desired.\n\nprint('Calibration data:')\nfor name in dir(sensor.calibration_data):\n\n    if not name.startswith('_'):\n        value = getattr(sensor.calibration_data, name)\n\n        if isinstance(value, int):\n            print('{}: {}'.format(name, value))\n\n# These oversampling settings can be tweaked to\n# change the balance between accuracy and noise in\n# the data.\n\nsensor.set_humidity_oversample(bme680.OS_2X)\nsensor.set_pressure_oversample(bme680.OS_4X)\nsensor.set_temperature_oversample(bme680.OS_8X)\nsensor.set_filter(bme680.FILTER_SIZE_3)\nsensor.set_gas_status(bme680.ENABLE_GAS_MEAS)\n</code></pre> <p>The sensor = bme680.BME680() command creates an instance of the sensor that we\u2019ll use to configure the settings and get the sensor\u2019s readings. The _oversample settings we established for the humidity, pressure, and temperature measurements are designed to strike a balance between accurate readings and minimizing noise. The higher the oversampling, the greater the noise reduction, albeit accompanied by a reduction in accuracy.</p> <p>The _filter protects sensor readings against transient changes in conditions, e.g. a door slamming that could cause the pressure to change momentarily, and the IIR filter removes these transient spiky values.</p> <p>Shown in the code below, the gas measurement has a few settings that can be tweaked. It can be enabled or disabled with set_gas_status. Disabling it allows the other readings to be taken more rapidly, as mentioned above. The temperature of the hot plate and how long it\u2019s held at that temperature can also be altered, although we recommend not changing these settings if your gas resistance readings look sensible.</p> <pre><code>print('\\n\\nInitial reading:')\nfor name in dir(sensor.data):\n    value = getattr(sensor.data, name)\n\n    if not name.startswith('_'):\n        print('{}: {}'.format(name, value))\n\nsensor.set_gas_heater_temperature(320)\nsensor.set_gas_heater_duration(150)\nsensor.select_gas_heater_profile(0)\n\n# Up to 10 heater profiles can be configured, each\n# with their own temperature and duration.\n# sensor.set_gas_heater_profile(200, 150, nb_profile=1)\n# sensor.select_gas_heater_profile(1)\n\n\nparser = argparse.ArgumentParser()\nparser.add_argument(\"--port\", type=int, help=\"redis instance port\", default=6379)\nparser.add_argument(\n    \"--password\", type=int, help=\"redis instance password\", default=None\n)\nparser.add_argument(\"--verbose\", help=\"enable verbose output\", action=\"store_true\")\nparser.add_argument(\"--host\", type=str, help=\"redis instance host\", default=\"127.0.0.1\")\n\n\nargs = parser.parse_args()\n</code></pre> <p>Next, we define the Redis connector, where we specify the Redis instance host, port, and password. As shown below, the code below defines the various RedisTimeSeries keys, such as a temperature key (TS:TEMPERATURE), pressure key (TS:PRESSURE), and humidity key (TS:HUMIDITY).</p> <pre><code># redis setup\nredis_obj = redis.Redis(host=args.host, port=args.port, password=args.password)\ntemperature_key = \"ts:temperature\"\npressure_key = \"ts:pressure\"\nhumidity_key = \"ts:humidity\"\n</code></pre> <p>The sensor.get_sensor_data() instruction gets the data from the sensor and populates the three variables with temperature, humidity, and pressure.</p> <pre><code>print('\\n\\nPolling:')\ntry:\n    while True:\n        if not sensor.get_sensor_data():\n            continue\n\n        output = '{0:.2f} C,{1:.2f} hPa,{2:.2f} %RH'.format(\n            sensor.data.temperature,\n            sensor.data.pressure,\n            sensor.data.humidity)\n\n        if not sensor.data.heat_stable:\n            print('Heat unstable: ' + output)\n            continue\n\n        print('{0},{1} Ohms'.format(\n            output,\n            sensor.data.gas_resistance))\n\n        date = datetime.datetime.now()\n        timestamp = int(date.timestamp() * 1000)\n\n        # Create pipeline\n        pipe = redis_obj.pipeline()\n\n        pipe.execute_command(\n            \"ts.add\", temperature_key, timestamp, sensor.data.temperature\n        )\n\n        pipe.execute_command(\n            \"ts.add\", pressure_key, timestamp, sensor.data.pressure\n        )\n\n        pipe.execute_command(\"ts.add\", humidity_key,\n                             timestamp, sensor.data.humidity)\n\n        # Execute pipeline\n        pipe.execute()\n        time.sleep(1)\n\nexcept KeyboardInterrupt:\n    pass\n</code></pre> <p>Next, a \u201ctransactional pipeline\u201d is constructed by calling the .pipeline() method on a Redis connection without arguments. Under the covers, the pipeline collects all the commands that are passed until the .execute() method is called. As you can see, we used RedisTimeSeries\u2019 TS.ADD command to populate the sensor data structure. You can access the complete code via this GitHub Repository.</p>"},{"location":"nvidia/redis-grafana-docker/#step-8-execute-the-script","title":"Step 8: Execute the script","text":"<p>Before you execute the script, you will need to import the bme680 and smbus Python modules, as shown here:</p> <pre><code>$ pip3 install bme680\n</code></pre> <pre><code>$ pip3 install smbus\n</code></pre> <p>Make sure you supply the right Redis Enterprise Cloud database endpoints, username, and password:</p> <pre><code>$ python3 sensorloader.py --host &lt;Redis Enterprise Cloud host&gt; --port &lt;port&gt;  --password &lt;password&gt; \n</code></pre> <p>You can run the monitor command to verify that sensor data is being populated, as shown here:</p> <pre><code>$ redis-cli -h redis-12929.c212.ap-south-1-1.ec2.cloud.redislabs.com -p 12929\nredis-12929.c212.ap-south-1-1.ec2.cloud.redislabs.com:12929&gt; auth &lt;password&gt;\nOK\nredis-12929.c212.ap-south-1-1.ec2.cloud.redislabs.com:12929&gt; monitor\nOK\n1611046300.446452 [0 122.179.79.106:53715] \"info\" \"server\"\n1611046300.450452 [0 122.179.79.106:53717] \"info\" \"stats\"\n1611046300.450452 [0 122.179.79.106:53716] \"info\" \"clients\"\n1611046300.486452 [0 122.179.79.106:53714] \"info\" \"memory\"\n1611046300.486452 [0 122.179.79.106:53713] \"info\" \"server\"\n1611046300.494452 [0 122.179.79.106:53715] \"info\" \"memory\"\n1611046300.498452 [0 122.179.79.106:53717] \"info\" \"commandstats\"\n1611046300.522452 [0 122.179.79.106:53716] \"dbsize\"\n1611046301.498452 [0 122.179.79.106:53714] \"info\" \"memory\"\n1611046301.498452 [0 122.179.79.106:53713] \"info\" \"server\"\n1611046301.498452 [0 122.179.79.106:53715] \"info\" \"server\"\n1611046301.498452 [0 122.179.79.106:53716] \"info\" \"clients\"\n1611046301.498452 [0 122.179.79.106:53717] \"info\" \"stats\"\n1611046301.554452 [0 122.179.79.106:53714] \"info\" \"memory\"\n1611046301.562452 [0 122.179.79.106:53717] \"info\" \"commandstats\"\n</code></pre>"},{"location":"nvidia/redis-grafana-docker/#step-9-deploy-grafana","title":"Step 9: Deploy Grafana","text":"<p>It\u2019s exciting to see the sensor data plotted in Grafana. To implement this, run the command below:</p> <pre><code>$ docker run -d -e \"GF_INSTALL_PLUGINS=redis-app\" -p 3000:3000 grafana/grafana\n</code></pre> <p>Be sure that you have Docker Engine running in your system, either on your desktop system or in the cloud. For this demonstration, I have tested it on Docker Desktop for Mac.</p> <p>Point your browser to https://:3000. Use \u201cadmin\u201d as username and password to log in to the Grafana dashboard. <p></p> <p>Click the Data Sources option on the left side of the Grafana dashboard to add a data source.</p> <p></p> <p>Under the Add data source option, search for Redis and the Redis data source will appear as shown below:</p> <p></p> <p></p> <p>Supply the name, Redis Enterprise Cloud database endpoint, and password, then click Save &amp; Test.</p> <p></p> <p>Click Dashboards to import Redis and Redis Streaming. Click Import for both these options.</p> <p></p> <p>Click on Redis to see a fancy Grafana dashboard that shows the Redis database information:</p> <p></p> <p></p>"},{"location":"nvidia/redis-grafana-docker/#step-10-plot-redistimeseries-sensor-data-in-grafana","title":"Step 10: Plot RedisTimeSeries sensor data in Grafana","text":"<p>Finally, let\u2019s create a sensor dashboard that shows temperature, pressure, and humidity. To start with temperature,  first click on + on the left navigation window. Under Create option, Select Dashboard and click on the Add new panel button.</p> <p></p> <p>A new window will open showing the Query section. Select SensorT from the drop-down menu, choose RedisTimeSeries as type, TS.GET as command and ts\u201dtemperature as key.</p> <p></p> <p>Choose TS.GET as a command.</p> <p></p> <p>Type ts\u201dtemperature as the key.</p> <p></p> <p>Click Run followed by Save, as shown below:</p> <p></p> <p>Now you can save the dashboard by your preferred name:</p> <p>Click Save.This will open up a sensor dashboard. You can click on Panel Title and select Edit.</p> <p></p> <p>Type Temperature and choose Gauge under Visualization.</p> <p></p> <p>Click Apply and you should be able to see the temperature dashboard as shown here:</p> <p></p> <p>Follow the same process for pressure (ts:pressure) and humidity (ts:humidity), and add them to the dashboard. You should be able to see the complete dashboard readings for temperature, humidity, and pressure. Looks amazing. Isn\u2019t it?</p> <p></p> <p>Follow us over Twitter:  - https://twitter.com/collabnix</p>"},{"location":"raspberrypi/docker-on-raspberrypi/","title":"Install Docker on Rasperry Pi","text":"<p>Raspberry Pi boards today are not just limited to hobbyists and makers. It is heavily used in the IoT industry as a preferable solution for Linux Edge computing. The Raspberry Pi is a tiny computer about the size of a deck of cards. It uses what\u2019s called a system on a chip, which integrates the CPU and GPU in a single integrated circuit, with the RAM, USB ports, and other components soldered onto the board for an all-in-one package. One can use Raspberry Pi to learn programming skills, build hardware projects, do home automation, implement Kubernetes clusters and Edge computing, and even use them in industrial applications. </p> <p>Docker support for Raspberry Pi was introduced for the first time in 2016 with v1.12 release. At the same time, Rancher community introduced a lightweight Kubernetes distribution(a.k.a. K3s) for Pi box. K3s is a brand new distribution of Kubernetes that is designed for teams that need to deploy applications quickly and reliably to resource-constrained environments. K3s is a Certified Kubernetes distribution designed for production workloads in unattended, resource-constrained, remote locations or inside IoT appliances.</p>"},{"location":"raspberrypi/docker-on-raspberrypi/#why-docker-kubernetes-on-iot-devices","title":"Why Docker &amp; Kubernetes on IoT devices?","text":"<p>Today many organizations are going through a digital transformation process. Digital transformation is the integration of digital technology into almost all areas of a business, fundamentally changing how you operate and deliver value to customers. It\u2019s basically a cultural change.  The common goal for all these organization is to change how they connect with their customers, suppliers and partners. These organizations are taking advantage of innovations offered by technologies such as IoT platforms, big data analytics, or machine learning to modernize their enterprise IT and OT systems. They realize that the complexity of development and deployment of new digital products require new development processes. Consequently, they turn to agile development and infrastructure tools such as Kubernetes.</p> <p>Docker containers &amp; Kubernetes are an excellent choice for deploying complex software to the Edge. The reasons are listed below:</p> <ul> <li>Containers are awesome</li> <li>Consistent across a wide variety of Infrastructure</li> <li>Capable of standalone or clustered operations</li> <li>Easy to upgrade and/or replace containers</li> <li>Support for different infrastructure configs(storage,CPU etc.)</li> <li>Strong Ecosystem(Monitoring, logging, CI, management etc.)</li> </ul> <p>In the first part of this blog post, I will show you how to install the latest version of Docker on the Raspberry Pi board in 5 Minutes.</p>"},{"location":"raspberrypi/docker-on-raspberrypi/#hardware","title":"Hardware:","text":"<ul> <li>Raspberry Pi 4 ( You can order it from Amazon in case you are in India for $35)</li> <li>Micro-SD card reader ( I got it from here )</li> <li>Any Windows or Linux Desktop or Laptop</li> <li>HDMI cable ( I used the HDMI cable of my plasma TV)</li> <li>Internet Connectivity(Wifi/Broadband/Tethering using Mobile) \u2013 to download Docker 1.12.1 package</li> <li>Keyboard &amp; mouse connected to Pi\u2019s USB ports</li> <li>Raspberry Pi OS (previously called Raspbian) is an official operating system for all models of the Raspberry Pi. We will be using Raspberry Pi Imager for an easy way to install Raspberry Pi OS on top of Raspberry Pi:</li> </ul> <p>Visit https://www.raspberrypi.org/downloads/raspberry-pi-os/ and download Raspberry Pi OS by running the below CLI:</p> <p></p> <p>Visit https://www.raspberrypi.org/downloads/raspberry-pi-os/ and download Raspberry Pi OS by running the below CLI:</p> <p>In case you are in hurry, just run the below command and you should be good to go:</p> <pre><code>wget https://downloads.raspberrypi.org/raspios_full_armhf_latest\ufeff\n</code></pre>"},{"location":"raspberrypi/docker-on-raspberrypi/#using-raspberry-pi-imager","title":"Using Raspberry Pi Imager","text":"<p>Next, we will be installing Raspberry Pi Imager. You can download via https://www.raspberrypi.org/blog/raspberry-pi-imager-imaging-utility/</p> <p></p> <p>All you need to do is choose the right operating system and SD card, and it should be able to flash OS on your SD card.</p> <p></p> <p>Click \u201cWrite\u201d and it\u2019s time to grab a coffee.</p> <p></p> <p>Once the write is successful, you can remove the SD card from card reader and then insert it into Raspberry Pi SD card slot.</p> <p></p> <p>SSH to Raspberry Pi nodes</p> <pre><code>$ssh pi@192.168.1.7$ssh pi @192.168.1.4\npi@raspberrypi:~ $ uname -arn\nLinux raspberrypi 4.19.118-v7+ #1311 SMP Mon Apr 27 14:21:24 BST 2022 armv7l GNU/Linuxpi@raspberrypi:~ $\n</code></pre>"},{"location":"raspberrypi/docker-on-raspberrypi/#step-2-installing-docker-201020-on-each-pi-nodes","title":"Step #2: Installing Docker 20.10.20 on each Pi nodes","text":"<pre><code>sudo curl -sSL https://get.docker.com/ | sh\npi@raspi2:~ $ docker version\nClient: Docker Engine - Community \nVersion:           20.10.20 \nAPI version:       1.41 \nGo version:        go1.12.10 \nGit commit:        baeda1f \nBuilt:             Tue Oct 25 18:01:18 2022 \nOS/Arch:           linux/arm \nExperimental:      false\n\nServer: Docker Engine - Community Engine:  \nVersion:          20.10.20  \nAPI version:      1.41 (minimum version 1.12)  \nGo version:       go1.18.7  \nGit commit:       3056208  \nBuilt:            Tue Oct 25 18:01:18 2022  \nOS/Arch:          linux/arm  \nExperimental:     false \ncontainerd:\n  Version:          1.6.9\n  GitCommit:        1c90a442489720eec95342e1789ee8a5e1b9536f\n runc:\n  Version:          1.1.4\n  GitCommit:        v1.1.4-0-g5fd4c4d\n docker-init:\n  Version:          0.19.0\n  GitCommit:        de40ad0\n</code></pre>"},{"location":"raspberrypi/docker-on-raspberrypi/#running-nginx-docker-container","title":"Running Nginx Docker container","text":"<pre><code>pi@raspi2:~ $ docker run -d -p 80:80 nginx\npi@raspi2:~ $ docker psCONTAINER ID        IMAGE               COMMAND                  CREATED             STATUS              PORTS                NAMESd7055f45bf23        nginx               \"/docker-entrypoint.\u2026\"   2 minutes ago       Up About a minute   0.0.0.0:80-&gt;80/tcp   silly_maxwellpi@raspi2:~ $\n</code></pre>"},{"location":"raspberrypi/getting-started/","title":"Getting Started with Rasperry Pi","text":"<p>The Raspberry Pi is a small, low-cost computer developed by the Raspberry Pi Foundation in the United Kingdom. It is intended to promote the teaching of basic computer science in schools and developing countries. The Raspberry Pi is about the size of a credit card and can be used for a variety of tasks including programming, web browsing, and playing videos. It runs on a Linux-based operating system and can be connected to a monitor, keyboard, and mouse to use as a desktop computer, or it can be used with a variety of accessories to control hardware or interact with the internet.</p> <p></p> <p>The Raspberry Pi is a low-cost, credit-card sized computer that plugs into a computer monitor or TV, and uses a standard keyboard and mouse. It is a capable little device that enables people of all ages to explore computing, and to learn how to program in languages like Scratch and Python. It's also used for a variety of DIY projects and as a media center, retro gaming console, and general-purpose computer. Additionally, it can be used for various purposes such as Robotics, home automation, and IoT projects, etc.</p>"},{"location":"raspberrypi/getting-started/#hardware","title":"Hardware:","text":"<ul> <li>Raspberry Pi 4 ( You can order it from Amazon in case you are in India for $35)</li> <li>Micro-SD card reader ( I got it from here )</li> <li>Any Windows or Linux Desktop or Laptop</li> <li>HDMI cable ( I used the HDMI cable of my plasma TV)</li> <li>Internet Connectivity(Wifi/Broadband/Tethering using Mobile) \u2013 to download Docker 1.12.1 package</li> <li>Keyboard &amp; mouse connected to Pi\u2019s USB ports</li> <li>Raspberry Pi OS (previously called Raspbian) is an official operating system for all models of the Raspberry Pi. We will be using Raspberry Pi Imager for an easy way to install Raspberry Pi OS on top of Raspberry Pi:</li> </ul> <p>Insert the microSD card into your Pi box. Now connect the HDMI cable  from one end of Pi\u2019s HDMI slot to your TV or display unit and mobile charger(recommended 5.1V@1.5A) as shown:</p> <p></p> <p>Visit https://www.raspberrypi.org/downloads/raspberry-pi-os/ and download Raspberry Pi OS by running the below CLI:</p> <p></p> <p>Visit https://www.raspberrypi.org/downloads/raspberry-pi-os/ and download Raspberry Pi OS by running the below CLI:</p> <p>In case you are in hurry, just run the below command and you should be good to go:</p> <pre><code>wget https://downloads.raspberrypi.org/raspios_full_armhf_latest\ufeff\n</code></pre>"},{"location":"raspberrypi/getting-started/#using-raspberry-pi-imager","title":"Using Raspberry Pi Imager","text":"<p>Next, we will be installing Raspberry Pi Imager. You can download via https://www.raspberrypi.org/blog/raspberry-pi-imager-imaging-utility/</p> <p></p> <p>All you need to do is choose the right operating system and SD card, and it should be able to flash OS on your SD card.</p> <p></p> <p>Click \u201cWrite\u201d and it\u2019s time to grab a coffee.</p> <p></p> <p>Once the write is successful, you can remove the SD card from card reader and then insert it into Raspberry Pi SD card slot.</p> <p></p> <p>SSH to Raspberry Pi nodes</p> <pre><code>$ssh pi @192.168.1.4\npi@raspberrypi:~ $ uname -arn\nLinux raspberrypi 4.19.118-v7+ #1311 SMP Mon Apr 27 14:21:24 BST 2022 armv7l GNU/Linuxpi@raspberrypi:~ $\n</code></pre>"},{"location":"raspberrypi/projects/GPS/getting-started/","title":"Using GPS","text":"<p>NEO-6M GPS Module with EPROM is a complete GPS module that is based on the NEO 6M GPS. This unit uses the latest technology to give the best possible positioning information and includes a larger built-in 25 x 25mm active GPS antenna with a UART TTL socket. A battery is also included so that you can obtain a GPS lock faster. This is an updated GPS module that can be used with ardupilot mega v2. This GPS module gives the best possible position information, allowing for better performance with your Ardupilot or other Multirotor control platform.</p> <p>The GPS module has serial TTL output, it has four pins: TX, RX, VCC, and GND. You can download the u-centre software for configuring the GPS and changing the settings and much more. It is really good software (see link below).</p>"},{"location":"raspberrypi/projects/GPS/getting-started/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Intent</li> <li>Hardware</li> <li>Software</li> <li>Connect GPS Module to Rasberry Pi</li> <li>Ploting the GPS Values over Google Map</li> <li>Stream Data Over PubNub</li> </ol>"},{"location":"raspberrypi/projects/GPS/getting-started/#intent","title":"Intent","text":"<p>How to connect GPS to Raspberry Pi or Arduino, fetch the latitude and longitude values and plot it over Google Map</p>"},{"location":"raspberrypi/projects/GPS/getting-started/#hardware","title":"Hardware","text":"<ul> <li>Raspberry Pi/Arduino</li> <li>NEO-6M GPS Module with EPROM</li> </ul>"},{"location":"raspberrypi/projects/GPS/getting-started/#software","title":"Software","text":"<ul> <li>Flash Rapsberry Pi SD card with OS using Etcher</li> </ul>"},{"location":"raspberrypi/projects/GPS/getting-started/#connect-the-gps-module-to-the-raspberry-pi","title":"Connect the GPS module to the Raspberry PI.","text":"<p>There are only 4 wires (F to F), so it's a simple connection.</p> <p></p> <ul> <li> <p>Neo-6M RPI</p> </li> <li> <p>VCC to Pin 1, which is 3.3v</p> </li> <li> <p>TX to Pin 10, which is RX (GPIO15)</p> </li> <li> <p>RX to Pin 8, Which is TX (GPIO14)</p> </li> <li> <p>Gnd to Pin 6, which is Gnd</p> </li> </ul> <p></p>"},{"location":"raspberrypi/projects/GPS/getting-started/#turn-off-the-serial-console","title":"Turn Off the Serial Console","text":"<p>By default, the Raspberry Pi uses the UART as a serial console. We need to turn off that functionality so that we can use the UART for our own application. Open a terminal session on the Raspberry Pi.</p>"},{"location":"raspberrypi/projects/GPS/getting-started/#step-1-backup-the-file-cmdlinetxt","title":"Step 1. Backup the file cmdline.txt","text":"<pre><code>sudo cp /boot/cmdline.txt /boot/cmdline_backup.txt \n</code></pre>"},{"location":"raspberrypi/projects/GPS/getting-started/#step-2-edit-cmdlinttxt-and-remove-the-serial-interface","title":"Step 2. Edit cmdlint.txt and remove the serial interface","text":"<pre><code>sudo nano /boot/cmdline.txt\n</code></pre>"},{"location":"raspberrypi/projects/GPS/getting-started/#step-3-delete-consolettyama0115200","title":"Step 3. Delete console=ttyAMA0,115200","text":"<p>Once you delete it, save the file by pressing Ctrl X, Y, and Enter.</p>"},{"location":"raspberrypi/projects/GPS/getting-started/#step-4-edit-etcinittab","title":"Step 4. Edit /etc/inittab","text":"<pre><code>sudo nano /etc/inittab \n</code></pre>"},{"location":"raspberrypi/projects/GPS/getting-started/#step-5-find-ttyama0","title":"Step 5. Find ttyAMA0","text":"<p>You can find ttyAMA0 by pressing Ctrl W and typing ttyAMA0 on the search line</p> <p>Press Home &gt; insert a # symbol to comment out that line and Ctrl X, Y, Enter to save.</p> <pre><code>sudo reboot\n</code></pre>"},{"location":"raspberrypi/projects/GPS/getting-started/#step-6-test-the-gps","title":"Step 6. Test the GPS","text":"<p>Open a terminal session and type </p> <pre><code>sudo apt-get install gpsd gpsd-clients\n</code></pre>"},{"location":"raspberrypi/projects/GPS/getting-started/#step-7-start-the-serial-port","title":"Step 7. Start the serial port:","text":"<pre><code>stty -F /dev/ttyAMA0 9600\n</code></pre> <p>Now start GPSD:</p> <pre><code>sudo gpsd /dev/ttyAMA0 -F /var/run/gpsd.sock\n</code></pre>"},{"location":"raspberrypi/projects/GPS/getting-started/#step-8-final-results","title":"Step 8. Final Results","text":"<pre><code>cgps -s\n</code></pre>"},{"location":"raspberrypi/projects/GPS/getting-started/#fetching-the-values","title":"Fetching the Values","text":""},{"location":"raspberrypi/projects/GPS/getting-started/#clone-the-repository","title":"Clone the repository","text":"<pre><code>git clone https://github.com/collabnix/cherrybot\ncd cherrybot/pubnub/\n</code></pre>"},{"location":"raspberrypi/projects/GPS/getting-started/#fetching-the-gps-values","title":"Fetching the GPS values","text":"<pre><code>python3 gps.py\n</code></pre> <pre><code>Latitude=12.9814865and Longitude=77.6683425\nLatitude=12.9814848333and Longitude=77.6683436667\nLatitude=12.9814841667and Longitude=77.6683451667\nLatitude=12.9814818333and Longitude=77.6683461667\nLatitude=12.9814853333and Longitude=77.6683491667\nLatitude=12.9814783333and Longitude=77.6683485\nLatitude=12.9814701667and Longitude=77.6683466667\nLatitude=12.981464and Longitude=77.668345\nLatitude=12.9814586667and Longitude=77.6683438333\nLatitude=12.9814525and Longitude=77.6683428333\nLatitude=12.9814458333and Longitude=77.6683421667\nLatitude=12.9814395and Longitude=77.6683421667\nLatitude=12.9814331667and Longitude=77.668342\nLatitude=12.981428and Longitude=77.6683425\nLatitude=12.981423and Longitude=77.6683428333\nLatitude=12.9814185and Longitude=77.6683431667\nLatitude=12.9814146667and Longitude=77.6683436667\nLatitude=12.9814095and Longitude=77.6683443333\nLatitude=12.9814056667and Longitude=77.6683456667\nLatitude=12.981401and Longitude=77.668346\nLatitude=12.9813966667and Longitude=77.66834\n</code></pre>"},{"location":"raspberrypi/projects/GPS/getting-started/#ploting-the-gps-values-over-google-map","title":"Ploting the GPS Values over Google Map","text":""},{"location":"raspberrypi/projects/GPS/getting-started/#stream-data-over-pubnub","title":"Stream Data Over PubNub","text":"<p>If you haven\u2019t already done so, sign up for a free PubNub account before you begin this step.</p>"},{"location":"raspberrypi/projects/GPS/getting-started/#change-directory","title":"Change directory","text":"<p>Change directory into the examples directory containing the gps_simpletest.py file and install the PubNub Python SDK.</p> <pre><code>pip3 install pubnub\n</code></pre>"},{"location":"raspberrypi/projects/GPS/getting-started/#import-pubnub-package","title":"Import PubNub Package","text":"<pre><code>import pubnub\nfrom pubnub.pnconfiguration import PNConfiguration\nfrom pubnub.pubnub import PubNub\nfrom pubnub.callbacks import SubscribeCallback\nfrom pubnub.enums import PNOperationType, PNStatusCategory\n</code></pre>"},{"location":"raspberrypi/projects/GPS/getting-started/#configure-a-pubnub-instance-with-your-publishsubscribe-keys","title":"Configure a PubNub instance with your publish/subscribe Keys","text":"<pre><code>pnconfig = PNConfiguration()\npnconfig.subscribe_key = \"YOUR SUBSCRIBE KEY\"\npnconfig.publish_key = \"YOUR PUBLISH KEY\"\npnconfig.ssl = False\npubnub = PubNub(pnconfig)\n</code></pre> <p>Then to publish, place a publishing callback somewhere near the beginning of your code. You can write whatever you want for the callback, but we\u2019ll leave it blank as we don\u2019t really need it for now.</p> <pre><code>def publish_callback(result, status):\n    pass\n    # Handle PNPublishResult and PNStatus\n</code></pre> <p>Here is where you decide what data you want to publish. Since we are building just a simple GPS tracking device, we\u2019re just going to be dealing with the latitude and longitude coordinates.</p> <p>When you want to publish multiple variables in one JSON, you must create a dictionary like so:</p> <pre><code>dictionary = {\"DATA 1 NAME\": gps.DATA1, \"DATA 2 NAME\": gps.DATA2}\n</code></pre> <p>So in our case we would write:</p> <pre><code>dictionary = {\"latitude\": gps.latitude, \"longitude\": gps.longitude}\n</code></pre> <p>And then to publish that data, you would format the dictionary like this:</p> <pre><code>pubnub.publish().channel(\"CHANNEL\").message(dictionary).pn_async(publish_callback)\n</code></pre> <p>It is best to place the dictionary and publishing lines within the \u201cif gps.DATA is not none\u201d to avoid any program failures.</p>"},{"location":"raspberrypi/projects/GPS/getting-started/#visualize-your-gps-data-with-google-maps","title":"Visualize your GPS Data with Google Maps","text":"<p>It's time to visualize our GPS data in a way that humans can understand.</p> <p>We\u2019re just going to create a small HTML page that will grab GPS data from our PubNub channel and graph the data with a geolocation API.</p>"},{"location":"raspberrypi/projects/GPS/getting-started/#google-maps-api","title":"Google Maps API","text":"<p>The Google Maps API is a universal tool that is not only one of the cheaper APIs for a greater amount of API calls but also has a rich and expansive toolset for developers. The GPS data is not only more accurate than most other APIs, but also has extensive tools such as \u201cETA\u201d that uses Google\u2019s geographical terrain data.</p> <p>So if you ever want to build a serious GPS tracking app with PubNub, Google Maps is the way to go.</p> <p>Image result for google maps api with marker</p> <p>You\u2019ll first need to get a Google Maps API Key</p> <p>Once that\u2019s done, create an .html file and copy-paste the code below (explanation of the code is below as well).</p> <pre><code>&lt;!DOCTYPE html&gt;\n&lt;html&gt;\n  &lt;head&gt;\n    &lt;title&gt;Simple Map&lt;/title&gt;\n    &lt;meta name=\"viewport\" content=\"initial-scale=1.0\"&gt;\n    &lt;meta charset=\"utf-8\"&gt;\n    &lt;style&gt;\n      /* Always set the map height explicitly to define the size of the div\n       * element that contains the map. */\n      #map {\n        height: 100%;\n      }\n      /* Optional: Makes the sample page fill the window. */\n      html, body {\n        height: 100%;\n        margin: 0;\n        padding: 0;\n      }\n    &lt;/style&gt;\n    &lt;script src=\"https://cdn.pubnub.com/sdk/javascript/pubnub.4.23.0.js\"&gt;&lt;/script&gt;\n  &lt;/head&gt;\n  &lt;body&gt;\n    &lt;div id=\"map\"&gt;&lt;/div&gt;\n    &lt;script&gt;\n  // the smooth zoom function\n  function smoothZoom (map, max, cnt) {\n      if (cnt &gt;= max) {\n          return;\n      }\n      else {\n          z = google.maps.event.addListener(map, 'zoom_changed', function(event){\n              google.maps.event.removeListener(z);\n              smoothZoom(map, max, cnt + 1);\n          });\n          setTimeout(function(){map.setZoom(cnt)}, 80); // 80ms is what I found to work well on my system -- it might not work well on all systems\n      }\n  } \n    var pubnub = new PubNub({\n    subscribeKey: \"YOUR SUBSCRIBE KEY\",\n    ssl: true\n  });  \n  var longitude = 30.5;\n  var latitude = 50.5;\n  pubnub.addListener({\n      message: function(m) {\n          // handle message\n          var channelName = m.channel; // The channel for which the message belongs\n          var channelGroup = m.subscription; // The channel group or wildcard subscription match (if exists)\n          var pubTT = m.timetoken; // Publish timetoken\n          var msg = m.message; // The Payload\n          longitude = msg.longitude;\n          latitude = msg.latitude;\n          var publisher = m.publisher; //The Publisher\n    var myLatlng = new google.maps.LatLng(latitude, longitude);\n    var marker = new google.maps.Marker({\n        position: myLatlng,\n        title:\"PubNub GPS\"\n    });\n    // To add the marker to the map, call setMap();\n    map.setCenter(marker.position);\n    smoothZoom(map, 14, map.getZoom());\n    marker.setMap(map);\n      },\n      presence: function(p) {\n          // handle presence\n          var action = p.action; // Can be join, leave, state-change or timeout\n          var channelName = p.channel; // The channel for which the message belongs\n          var occupancy = p.occupancy; // No. of users connected with the channel\n          var state = p.state; // User State\n          var channelGroup = p.subscription; //  The channel group or wildcard subscription match (if exists)\n          var publishTime = p.timestamp; // Publish timetoken\n          var timetoken = p.timetoken;  // Current timetoken\n          var uuid = p.uuid; // UUIDs of users who are connected with the channel\n      },\n      status: function(s) {\n          var affectedChannelGroups = s.affectedChannelGroups;\n          var affectedChannels = s.affectedChannels;\n          var category = s.category;\n          var operation = s.operation;\n      }\n  });\n  pubnub.subscribe({\n      channels: ['ch1'],\n  });\n      var map;\n      function initMap() {\n        map = new google.maps.Map(document.getElementById('map'), {\n          center: {lat: latitude, lng: longitude},\n          zoom: 8\n        });\n      }\n    &lt;/script&gt;\n    &lt;script src=\"https://maps.googleapis.com/maps/api/js?key=AIzaSyBLuWQHjBa9SMVVDyyqxqTpR2ZwnxwcbGE&amp;callback=initMap\"\n    async defer&gt;&lt;/script&gt;\n  &lt;/body&gt;\n&lt;/html&gt;\n</code></pre> <p>This part of the code is responsible for rendering our map on the HTML page.</p> <pre><code>&lt;style&gt;\n  /* Always set the map height explicitly to define the size of the div\n   * element that contains the map. */\n  #map {\n    height: 100%;\n  }\n  /* Optional: Makes the sample page fill the window. */\n  html, body {\n    height: 100%;\n    margin: 0;\n    padding: 0;\n  }\n&lt;/style&gt;\n</code></pre> <p>Just a little below it, we enter a div id tag to tell where we want the map to render:</p> <p>//div tag for map[] id      </p> <p>Here we simply import the PubNub JS SDK to enable PubNub data streaming for our GPS data:</p> <pre><code>&lt;script src=\"https://cdn.pubnub.com/sdk/javascript/pubnub.4.23.0.js\"&gt;&lt;/script&gt;\n</code></pre> <p>We must also import the Google Maps API with this script tag:</p> <pre><code>&lt;script src=\"https://maps.googleapis.com/maps/api/js?key=YOURAPIKEY&amp;callback=initMap\"async defer&gt;&lt;/script&gt;\n</code></pre> <p>NOTE: The rest of the code is encapsulated within one script tag, so don\u2019t be alarmed if we jump around in explaining this final part of the code.</p> <p>In order to stream our data, instantiate a PubNub instance:</p> <pre><code>var pubnub = new PubNub({\n    subscribeKey: \"YOUR SUBSCRIBE KEY\",\n    ssl: true\n  });\n</code></pre> <p>Then we instantiate a PubNub listener with the following code.</p> <pre><code>pubnub.addListener({\n      message: function(m) {\n          // handle message\n          var channelName = m.channel; // The channel for which the message belongs\n          var channelGroup = m.subscription; // The channel group or wildcard subscription match (if exists)\n          var pubTT = m.timetoken; // Publish timetoken\n          var publisher = m.publisher; //The Publisher\n\n          var msg = m.message; // The Payload\n          //extract and save the longitude and latitude data from your incomming PubNub message\n          longitude = msg.longitude;\n          latitude = msg.latitude;\n\n        //Create a new Google Maps instance with updated GPS coordinates\n      var myLatlng = new google.maps.LatLng(latitude, longitude);\n      //Create a marker instance with the coordinates\n      var marker = new google.maps.Marker({\n          position: myLatlng,\n          title:\"PubNub GPS\"\n      });\n\n      //center the map with the maker position\n      map.setCenter(marker.position);\n      //Optional: create a zooming annimation when the gps changes coordinates\n      smoothZoom(map, 14, map.getZoom());\n      // To add the marker to the map, call setMap();\n      marker.setMap(map);\n      },\n      presence: function(p) {\n          // handle presence\n          var action = p.action; // Can be join, leave, state-change or timeout\n          var channelName = p.channel; // The channel for which the message belongs\n          var occupancy = p.occupancy; // No. of users connected with the channel\n          var state = p.state; // User State\n          var channelGroup = p.subscription; //  The channel group or wildcard subscription match (if exists)\n          var publishTime = p.timestamp; // Publish timetoken\n          var timetoken = p.timetoken;  // Current timetoken\n          var uuid = p.uuid; // UUIDs of users who are connected with the channel\n      },\n      status: function(s) {\n          var affectedChannelGroups = s.affectedChannelGroups;\n          var affectedChannels = s.affectedChannels;\n          var category = s.category;\n          var operation = s.operation;\n      }\n  });\n</code></pre> <p>In order to avoid syntax errors, place a subscriber instance right below the listener.</p> <pre><code>pubnub.subscribe({\n      channels: ['YOUR CHANNEL NAME'],\n  });\n</code></pre> <p>As you can see, we open up incoming messages with the following line of code.</p> <pre><code>var msg = m.message; // The Payload\n</code></pre> <p>And then extract the variables we desire based on the sent JSON.</p> <pre><code>longitude = msg.longitude;\nlatitude = msg.latitude;\n</code></pre> <p>We then format the data variables in accordance to a Google Maps object.</p> <pre><code>var myLatlng = new google.maps.LatLng(latitude, longitude);\n</code></pre> <p>To set a Google marker on our GPS coordinates we create a Google Maps marker object.</p> <pre><code>var marker = new google.maps.Marker({\n          position: myLatlng,\n          title:\"Title of Marker\"\n      });\n</code></pre> <p>Then add the marker to your Google Maps object by calling setMap().</p> <pre><code>marker.setMap(map);\n</code></pre> <p>Of course, it would be nice to center our map on the marker so we can actually see it so we center it on the markers position.</p> <pre><code>map.setCenter(marker.position);\n</code></pre> <p>This is optional, but if you want to add a smooth zooming animation every time you locate a marker, call a smoothZoom function like so.</p> <pre><code>smoothZoom(map, 14, map.getZoom());\n</code></pre> <p>And implement the smoothZoom function somewhere.</p> <pre><code>function smoothZoom (map, max, cnt) {\n      if (cnt &gt;= max) {\n          return;\n      }\n      else {\n          z = google.maps.event.addListener(map, 'zoom_changed', function(event){\n              google.maps.event.removeListener(z);\n              smoothZoom(map, max, cnt + 1);\n          });\n          setTimeout(function(){map.setZoom(cnt)}, 80); // 80ms is what I found to work well on my system -- it might not work well on all systems\n      }\n  } \n</code></pre> <p>Lastly we\u2019ll need to initialize the map so we write:</p> <pre><code>var map;\n     function initMap() {\n       map = new google.maps.Map(document.getElementById('map'), {\n         center: {lat: latitude, lng: longitude},\n         zoom: 8\n       });\n     }\n</code></pre> <p>And set the initial values of your latitude and longitude variables to wherever you want.</p> <pre><code>var longitude = 30.5;\nvar latitude = 50.5;\n</code></pre> <p>And that\u2019s it! </p>"},{"location":"raspberrypi/projects/GPS/getting-started/#fetch-the-values-over-google-map","title":"Fetch the values over Google Map","text":"<pre><code>open frontend.html\n</code></pre>"},{"location":"raspberrypi/projects/Pico/","title":"The Pico Project","text":"<p>Object Detection &amp; Text Analytics using Deep Learning Made Simple using Docker, Apache Kafka, IoT &amp; Amazon Rekognition System</p> <p></p>"},{"location":"raspberrypi/projects/Pico/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Intent</li> <li>Hardware</li> <li>Software</li> <li>Activating Raspberry Pi Camera</li> <li>Setting up Docker on Raspberry Pi</li> <li>Preparing Your Raspberry Pi</li> <li>Using Raspberry Pi Imager</li> <li>Installing Docker 19.03 on Raspberry Pi</li> <li>Setting up Apache Kafka running inside Docker container on AWS Cloud EC2 Instance</li> <li>Building up First Node using Docker Machine</li> <li>Building Apache Kafka on 2-Node Docker Swarm Cluster</li> <li>Setting up Pico</li> <li>Running Consumer Scripts on AWS Cloud Instance</li> <li>Running Producer Script on Raspberry Pi</li> <li>References &amp; Resources</li> </ol>"},{"location":"raspberrypi/projects/Pico/#intent","title":"Intent:","text":"<p>The intention with this project is to showcase how easy it is to implement object detection and analytics using Docker containers.Imagine you are able to capture live video streams, identify objects using deep learning, and then trigger actions or notifications based on the identified objects - all using Docker containers. With Pico, you will be able to setup and run a live video capture, analysis, and alerting solution prototype.</p> <p></p> <p>A camera surveils a particular area, streaming video over the network to a video capture client. The client samples video frames and sends them over to AWS, where they are analyzed and stored along with metadata. If certain objects are detected in the analyzed video frames, SMS alerts are sent out. Once a person receives an SMS alert, they will likely want to know what caused it. For that, sampled video frames can be monitored with low latency using a web-based user interface.</p> <p>The Pico framework uses Kafka cluster to acquire data in real-time. Kafka is a message-based distributed publish-subscribe system, which has the advantages of high throughput and perfect fault-tolerant mechanism. The type of data source is the video that generated by the cameras attached to Raspberry Pi. </p> <p></p>"},{"location":"raspberrypi/projects/Pico/#hardware","title":"Hardware","text":"Items Link Reference Raspberry Pi 3 Model B Buy Raspberry Pi Infrared IR Night Vision Surveillance Camera Module 500W Webcam Buy 5MP Raspberry Pi 3 Camera Module W/ HBV FFC Cable Buy"},{"location":"raspberrypi/projects/Pico/#software","title":"Software","text":"<ol> <li>Raspberry Pi OS</li> <li>Docker 19.03.x</li> <li>Python </li> <li>Amazon Cloud Subscription</li> <li>AWS Rekognition Service</li> </ol>"},{"location":"raspberrypi/projects/Pico/#activating-raspberry-pi-camera-module","title":"Activating Raspberry Pi Camera Module","text":"<p>To configure the camera Interface, run the below command as sudo or root user:</p> <pre><code>$ sudo raspi-config\n</code></pre> <p>It will open up command-line UI window, choose Interfacing , select Camera and enable it. Save and exit the CLI window.</p> <p>You will also need to load the required driver \u201cbcm2835-v412\u201d to make your camera module work. If you miss this step, you will end up seeing a blank screen even though the application comes up without any issue.</p> <pre><code># sudo modprobe bcm2835-v4l2\n</code></pre> <p></p>"},{"location":"raspberrypi/projects/Pico/#setting-up-docker-on-raspberry-pi","title":"Setting up Docker on Raspberry Pi","text":""},{"location":"raspberrypi/projects/Pico/#1-preparing-your-raspberry-pi","title":"1. Preparing Your Raspberry Pi","text":"<p>Raspberry Pi OS (previously called Raspbian) is an official operating system for all models of the Raspberry Pi. We will be using Raspberry Pi Imager for an easy way to install Raspberry Pi OS on top of Raspberry Pi:</p> <p>Visit this link and download Raspberry Pi OS by running the below CLI:</p> <p></p> <p>In case you are in hurry, just run the below command and you should be good to go:</p> <pre><code>wget https://downloads.raspberrypi.org/raspios_full_armhf_latest\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#2-using-raspberry-pi-imager","title":"2. Using Raspberry Pi Imager","text":"<p>Next, we will be installing Raspberry Pi Imager. You can download via https://www.raspberrypi.org/blog/raspberry-pi-imager-imaging-utility/</p> <p></p> <p>All you need to do is choose the right operating system and SD card, and it should be able to flash OS on your SD card.</p> <p></p> <p>Click \u201cWrite\u201d and it\u2019s time to grab a coffee.</p> <p></p> <p>Once the write is successful, you can remove the SD card from card reader and then insert it into Raspberry Pi SD card slot.</p> <p></p> <pre><code>$ssh pi @192.168.1.4\npi@raspberrypi:~ $ uname -arn\nLinux raspberrypi 4.19.118-v7+ #1311 SMP Mon Apr 27 14:21:24 BST 2020 armv7l GNU/Linuxpi@raspberrypi:~ $\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#3-installing-docker-1903-on-raspberry-pi","title":"3. Installing Docker 19.03 on Raspberry Pi","text":"<pre><code>sudo curl -sSL https://get.docker.com/ | sh\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#verifying-docker-binaries","title":"Verifying Docker Binaries","text":"<pre><code>pi@raspi2:~ $ docker version\nClient: Docker Engine - Community \nVersion:           19.03.4 \nAPI version:       1.40 \nGo version:        go1.12.10 \nGit commit:        9013bf5 \nBuilt:             Fri Oct 18 16:03:00 2019 \nOS/Arch:           linux/arm \nExperimental:      false\n\nServer: Docker Engine - Community Engine:  \nVersion:          19.03.8  \nAPI version:      1.40 (minimum version 1.12)  \nGo version:       go1.12.17  \nGit commit:       afacb8b  \nBuilt:            Wed Mar 11 01:29:22 2020  OS/Arch:          linux/arm  Experimental:     false \ncontainerd:  Version:          1.2.10  \nGitCommit:        b34a5c8af56e510852c35414db4c1f4fa6172339 \nrunc:  Version:          1.0.0-rc8+dev  \nGitCommit:        3e425f80a8c931f88e6d94a8c831b9d5aa481657 docker-init:  \nVersion:          0.18.0  \nGitCommit:        fec368\npi@raspi2:~ $\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#setting-up-apache-kafka-running-inside-docker-container-on-aws-cloud-ec2-instance","title":"Setting up Apache Kafka running inside Docker container on AWS Cloud EC2 Instance","text":""},{"location":"raspberrypi/projects/Pico/#pre-requisites","title":"Pre-requisites:","text":"<ul> <li>Docker Desktop for Mac or Windows</li> <li>AWS Account ( You will require t2.medium instances for this)</li> <li>AWS CLI installed</li> <li>Docker Machine installed</li> </ul>"},{"location":"raspberrypi/projects/Pico/#adding-your-credentials","title":"Adding Your Credentials:","text":"<pre><code>[Captains-Bay]\ud83d\udea9 &gt;  cat ~/.aws/credentials\n[default]\naws_access_key_id = XXXA \naws_secret_access_key = XX\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#verifying-aws-version","title":"Verifying AWS Version","text":"<pre><code>[Captains-Bay]\ud83d\udea9 &gt;  aws --version\naws-cli/1.11.107 Python/2.7.10 Darwin/17.7.0 botocore/1.5.70\nSetting up Environmental Variable\n</code></pre> <pre><code>[Captains-Bay]\ud83d\udea9 &gt;  export VPC=vpc-ae59f0d6\n[Captains-Bay]\ud83d\udea9 &gt;  export REGION=us-west-2a\n[Captains-Bay]\ud83d\udea9 &gt;  export SUBNET=subnet-827651c9\n[Captains-Bay]\ud83d\udea9 &gt;  export ZONE=a\n[Captains-Bay]\ud83d\udea9 &gt;  export REGION=us-west-2\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#building-up-first-node-using-docker-machine","title":"Building up First Node using Docker Machine","text":"<pre><code>[Captains-Bay]\ud83d\udea9 &gt;  docker-machine create  --driver amazonec2  --amazonec2-access-key=${ACCESS_KEY_ID}  --amazonec2-secret-key=${SECRET_ACCESS_KEY} --amazonec2-region=us-west-2 --amazonec2-vpc-id=vpc-ae59f0d6 --amazonec2-ami=ami-78a22900 --amazonec2-open-port 2377 --amazonec2-open-port 7946 --amazonec2-open-port 4789 --amazonec2-open-port 7946/udp --amazonec2-open-port 4789/udp --amazonec2-open-port 8080 --amazonec2-open-port 443 --amazonec2-open-port 80 --amazonec2-subnet-id=subnet-72dbdb1a --amazonec2-instance-type=t2.micro kafka-swarm-node1\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#listing-out-the-nodes","title":"Listing out the Nodes","text":"<pre><code>[Captains-Bay]\ud83d\udea9 &gt;  docker-machine ls\nNAME                ACTIVE   DRIVER      STATE     URL                         SWARM   DOCKER     ERRORS\nkafka-swarm-node1   -        amazonec2   Running   tcp://35.161.106.158:2376           v18.09.6   \nkafka-swarm-node2   -        amazonec2   Running   tcp://54.201.99.75:2376             v18.09.6 \n</code></pre>"},{"location":"raspberrypi/projects/Pico/#initialiating-docker-swarm-manager-node","title":"Initialiating Docker Swarm Manager Node","text":"<pre><code>ubuntu@kafka-swarm-node1:~$ sudo docker swarm init --advertise-addr 172.31.53.71 --listen-addr 172.31.53.71:2377\nSwarm initialized: current node (yui9wqfu7b12hwt4ig4ribpyq) is now a manager.\n\nTo add a worker to this swarm, run the following command:\n\n    docker swarm join --token SWMTKN-1-xxxxxmr075to2v3k-decb975h5g5da7xxxx 172.31.53.71:2377\n\nTo add a manager to this swarm, run 'docker swarm join-token manager' and follow the instructions.\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#adding-worker-node","title":"Adding Worker Node","text":"<pre><code>ubuntu@kafka-swarm-node2:~$ sudo docker swarm join --token SWMTKN-1-2xjkynhin0n2zl7xxxk-decb975h5g5daxxxxxxxxn 172.31.53.71:2377\nThis node joined a swarm as a worker.\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#verifying-2-node-docker-swarm-mode-cluster","title":"Verifying 2-Node Docker Swarm Mode Cluster","text":"<pre><code>ubuntu@kafka-swarm-node1:~$ sudo docker node ls\nID                            HOSTNAME            STATUS              AVAILABILITY        MANAGER STATUS      ENGINE VERSION\nyui9wqfu7b12hwt4ig4ribpyq *   kafka-swarm-node1   Ready               Active              Leader              18.09.6\nvb235xtkejim1hjdnji5luuxh     kafka-swarm-node2   Ready               Active                                  18.09.6\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#installing-docker-compose","title":"Installing Docker Compose","text":"<pre><code>curl -L https://github.com/docker/compose/releases/download/1.25.0-rc1/docker-compose-`uname -s`-`uname -m` -o /usr/local/bin/docker-compose\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100   617    0   617    0     0   2212      0 --:--:-- --:--:-- --:--:--  2211\n100 15.5M  100 15.5M    0     0  8693k      0  0:00:01  0:00:01 --:--:-- 20.1M\n</code></pre> <pre><code>root@kafka-swarm-node1:/home/ubuntu/dockerlabs/solution/kafka-swarm# chmod +x /usr/local/bin/docker-compose\n</code></pre> <pre><code>ubuntu@kafka-swarm-node1:~/dockerlabs/solution/kafka-swarm$ sudo docker-compose version\ndocker-compose version 1.25.0-rc1, build 8552e8e2\ndocker-py version: 4.0.1\nCPython version: 3.7.3\nOpenSSL version: OpenSSL 1.1.0j  20 Nov 2018\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#building-apache-kafka-on-2-node-docker-swarm-cluster","title":"Building Apache Kafka on 2-Node Docker Swarm Cluster","text":"<p>Apache Kafka is an open-source stream-processing software platform developed by LinkedIn and donated to the Apache Software Foundation. It is written in Scala and Java. The project aims to provide a unified, high-throughput, low-latency platform for handling real-time data feeds.</p> <p>Apache Kafka is a distributed, partitioned, and replicated publish-subscribe messaging system that is used to send high volumes of data, in the form of messages, from one point to another. It replicates these messages across a cluster of servers in order to prevent data loss and allows both online and offline message consumption. This in turn shows the fault-tolerant behaviour of Kafka in the presence of machine failures that also supports low latency message delivery. In a broader sense, Kafka is considered as a unified platform which guarantees zero data loss and handles real-time data feeds.</p>"},{"location":"raspberrypi/projects/Pico/#cloning-the-repository","title":"Cloning the Repository","text":"<pre><code>git clone https://github.com/ajeetraina/developer/solution/iot/ai/pico\ncd pico/kafka/\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#using-docker-stack-deploy-to-setup-3-node-kafka-cluster","title":"Using <code>docker stack deploy</code> to setup 3 Node Kafka Cluster","text":"<pre><code>docker stack deploy -c docker-compose.yml mykafka\n</code></pre> <p>By now, you should be able to access kafka manager at https://:9000"},{"location":"raspberrypi/projects/Pico/#adding-a-cluster","title":"Adding a cluster","text":"<ul> <li>Cluster Name = pico (or whatever you want)</li> <li>Cluster Zookeeper Hosts = zk-1:2181,zk-2:2181,zk-3:2181</li> <li>Kafka Version = leave it at 0.9.01 even though we're running 1.0.0</li> <li>Enable JMX Polling = enabled</li> </ul>"},{"location":"raspberrypi/projects/Pico/#adding-a-topic","title":"Adding a Topic","text":"<p>Click on Topic on the top center of the Kafka Manager to create a new topic with the below details -</p> <ul> <li>Topic = testpico</li> <li>Partitions = 6</li> <li>Replication factor = 2</li> </ul> <p>which gives an even spread of the topic across the three kafka nodes.</p> <p>While saving the settings, it might ask to set minimal parameter required. Feel free to follow the instruction provided.</p>"},{"location":"raspberrypi/projects/Pico/#setting-up-pico","title":"Setting up Pico","text":""},{"location":"raspberrypi/projects/Pico/#running-consumer-scripts-on-aws-cloud-instance","title":"Running Consumer Scripts on AWS Cloud Instance","text":"<p>Run the below Docker container for preparing environment for Consumer scripts</p> <pre><code>docker run -d -p 5000:5000 ajeetraina/opencv4-python3 bash\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#open-up-bash-shell-inside-docker-container","title":"Open up bash shell inside Docker Container","text":"<pre><code>docker exec -it &lt;container-id&gt; bash\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#remove-the-existing-pico-directory","title":"Remove the existing Pico directory","text":"<pre><code>rm -fr pico\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#cloning-the-fresh-repository","title":"Cloning the fresh Repository","text":"<pre><code>#git clone https://github.com/ajeetraina/developer/\ncd solutions/iot/ai/pico\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#locating-the-right-consumer-scripts","title":"Locating the right consumer scripts","text":"<p>You will need 2 scripts - Image Processor and Consumer</p> <pre><code>cd pico/deployment/objects/\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#execute-image-processor-script","title":"Execute Image processor Script","text":"<p>This script is placed under hhttps://github.com/ajeetraina/developer/edit/master/solutions/iot/ai/pico/blob/master/deployment/objects/image_processor.py location. Before you run this script, ensure that it has right AWS Access Key and Broker IP address</p> <pre><code>python3 image_processor.py\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#open-up-new-bash-again","title":"Open up new bash again","text":"<pre><code>docker exec -it &lt;container-id&gt; bash\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#exexute-consumer-script","title":"Exexute Consumer Script","text":"<p>This script is placed under https://github.com/ajeetraina/developer/edit/master/solutions/iot/ai/pico/blob/master/deployment/objects/ directory. Before you run this script, ensure that it has right Broker IP address</p> <pre><code>python3 consumer.py\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#running-producer-script-on-raspberry-pi","title":"Running Producer Script on Raspberry Pi","text":""},{"location":"raspberrypi/projects/Pico/#clone-the-repository","title":"Clone the Repository","text":"<pre><code>git clone https://github.com/ajeetraina/developer\ncd developer/solutions/iot/ai/pico\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#locating-producer-script","title":"Locating Producer Script","text":"<pre><code>cd pico/deployment/objects/\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#edit-producer_camerapy-script-and-add-the-proper-ip-address-for-the-kafka-broker","title":"Edit producer_camera.py script and add the proper IP address for the kafka broker:","text":"<pre><code>brokers = [\"35.221.213.182:9092\"]\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#installing-dependencies","title":"Installing Dependencies","text":"<pre><code>apt install -y python-pip libatlas-base-dev libjasper-dev libqtgui4 python3-pyqt5 python3-pyqt5 libqt4-test\npip3 install kafka-python opencv-python pytz\npip install virtualenv virtualenvwrapper numpy\n</code></pre>"},{"location":"raspberrypi/projects/Pico/#execute-the-script","title":"Execute the script","text":"<pre><code>python3 producer_camera.py\n</code></pre> <p>Please Note: This script should be run post the consumer scripts (Image_Processor &amp; Consumer.py) is executed</p>"},{"location":"raspberrypi/projects/Pico/#testing-object-detection","title":"Testing Object Detection","text":""},{"location":"raspberrypi/projects/Pico/#sequence-of-scripts-execution","title":"Sequence of Scripts Execution","text":""},{"location":"raspberrypi/projects/Pico/#pre-requisite","title":"Pre-requisite:","text":"<ul> <li>Ensure that you have followed all the above steps. </li> <li>Ensure that Docker Swarm is up and running on AWS Cloud</li> </ul>"},{"location":"raspberrypi/projects/Pico/#sequence","title":"Sequence:","text":"<ul> <li>First run the Image_Processor Script on AWS Instance</li> <li>Then run the Consumer.py Script on AWS Instance</li> <li>Finally, run the Producer_camera.py script on Pi</li> </ul> <p>Place an object in front of camera module and watch out for both text as well as object detection under http://broker-ip:5000</p> <p></p>"},{"location":"raspberrypi/projects/Pico/#references-resources","title":"References &amp; Resources","text":"<ul> <li>The Rise of Pico: At the Grace Hopper Celebration India</li> <li>Introducing Pico - Object Detection &amp; Analytics using Docker, IoT &amp; Amazon Rekognition System</li> </ul>"},{"location":"robomaster/getting-started/","title":"An Ultimate Tutorial for DJI Robomaster S1 Beginners","text":"<p>The RoboMaster S1 is an educational robot that provides users with an in-depth understanding of science, math, physics, programming, and more through captivating gameplay modes and intelligent features.</p>"},{"location":"robomaster/getting-started/#table-of-contents","title":"Table of Contents","text":"<ol> <li>Top 10 Features</li> <li>Stimulus that S1 Recognises</li> <li>Getting Started</li> <li>Items Check and Assembly</li> <li>Asembly the Mecanum Wheels</li> <li>Attaching the Gimbal to the Chassis</li> <li>Mounting the Gel Bead Container and Intelligent Battery</li> <li>Hacking into Robomaster S1</li> <li>References</li> </ol>"},{"location":"robomaster/getting-started/#top-10-features","title":"Top 10 Features","text":"<ul> <li>Support for Python and Scratch programming language</li> <li>46 Programmable Components - all in DIY mode</li> <li>6 Programmable AI Module</li> <li>Low-latency HD FPV</li> <li>Scratch &amp; Python Coding</li> <li>4WD Omnidirectional Movement</li> <li>Intelligent Sensing Armor</li> <li>Multiple Exciting Battle Modes</li> <li>Innovative Hands-On Learning</li> <li>Two shooting methods: gel beads and infrared beams.</li> <li>Capability to capture photos and record 1080p videos; without a microSD card, it supports only 720p.</li> </ul>"},{"location":"robomaster/getting-started/#stimulus-that-s1-recognises","title":"Stimulus that S1 recognises","text":"<ul> <li>Clapping Recognition: the S1 can recognize two or three consecutive claps and be programmed to execute custom responses.</li> <li>Gesture Recognition: the S1 can detect human gestures such as hand or arm signals and be programmed to execute custom responses.</li> <li>S1 Robot Recognition: the S1 can detect other RoboMaster S1 units.</li> <li>Vision Marker Recognition: the S1 can identify 44 kinds of official Vision Markers, which are comprised primarily of numbers, letters, and special characters. All of the files for these Vision Markers can be downloaded at insert web address.</li> <li>Line Recognition: the S1 can detect and follow blue, red, and green tracks with a width of approximately 15-25 mm.</li> </ul>"},{"location":"robomaster/getting-started/#how-it-works","title":"How it works?","text":"<ul> <li>The RoboMaster S1 can be operated using a computer or a smart device via the touchscreen and gamepad. When using the gamepad with a touchscreen device, the robot can also be operated using an external mouse, which can be connected through a dedicated USB port</li> <li>Users can connect to the RoboMaster S1 via Wi-Fi or a router. When connecting via Wi-Fi, your mobile device or computer connects to the Wi-Fi of the S1. Connection via router provides broader signal coverage, which allows multiple control methods for robots to operate simultaneously on the same network.</li> <li>Flat surfaces such as wood, carpet, tile, and concrete are optimal for operating the S1. Users should avoid surfaces that are too smooth as the S1 wheels may have problems gaining enough traction for precise control. Surfaces with fine particles like sand or dirt should be avoided.</li> </ul>"},{"location":"robomaster/getting-started/#table-of-contents_1","title":"Table of Contents","text":"<ol> <li>Getting Started</li> <li>Items Check and Assembly</li> <li>Asembly the Mecanum Wheels</li> <li>Attaching the Gimbal to the Chassis</li> <li>Mounting the Gel Bead Container and Intelligent Battery</li> <li>Hacking into Robomaster S1</li> </ol>"},{"location":"robomaster/getting-started/#getting-started","title":"Getting Started","text":"<ul> <li>Installing Robomaster Python Module on MacOS</li> </ul> <pre><code>conda create --name dji python=3.7\n</code></pre> <pre><code>conda activate dji\n</code></pre> <pre><code>pip install robomaster\n</code></pre>"},{"location":"robomaster/getting-started/#steps-to-assemble-robomaster","title":"Steps to assemble Robomaster","text":""},{"location":"robomaster/getting-started/#items-check-and-assembly","title":"Items Check and Assembly","text":""},{"location":"robomaster/getting-started/#assembly-the-mecanum-wheels","title":"Assembly the Mecanum Wheels","text":""},{"location":"robomaster/getting-started/#attaching-the-gimbal-to-the-chassis","title":"Attaching the Gimbal to the chassis","text":""},{"location":"robomaster/getting-started/#mounting-the-gel-bead-container-and-intelligent-battery","title":"Mounting the Gel Bead Container and Intelligent Battery","text":""},{"location":"robomaster/getting-started/#get-ready","title":"Get Ready!","text":""},{"location":"robomaster/getting-started/#hacking-into-robomaster","title":"Hacking into Robomaster","text":""},{"location":"robomaster/getting-started/#what-you-need","title":"What you need","text":"<ul> <li>Android SDK Platform\u2010Tools (https://developer.android.com/studio/releases/platform\u2010tools)</li> <li>Micro USB Cable</li> <li>Latest Robomaster S1 App &amp; Firmware</li> <li>Windows 10 (might or mightn't work for MacOS)</li> </ul>"},{"location":"robomaster/getting-started/#step-by-step-instructions","title":"Step by step instructions","text":"<ul> <li>Unzip the Android SDK Platform\u2010Tools somewhere in your system</li> <li>Use the Intelligent Controller Micro USB Port and connect the S1 to your computer.</li> <li>Start the Robomaster S1 application. Go to the Lab, create a new Python application and paste the following code:</li> </ul> <pre><code>def root_me(module):\n __import__=rm_log.__dict__['__builtins__']['__import__']\n return __import__(module,globals(),locals(),[],0)\nbuiltins=root_me('builtins')\nsubprocess=root_me('subprocess')\nproc=subprocess.Popen('/system/bin/adb_en.sh',shell=True,executable='\n/system/bin/sh',stdout=subprocess.PIPE,stderr=subprocess.PIPE)\n</code></pre> <ul> <li> <p>Run the Code within the S1 Lab. If you followed the steps correctly there should be no compilation errors. The Console will show: Execution Complete</p> </li> <li> <p>Don\u2019t close the S1 Application! Open an Explorer window and go to the directory which holds the earlier extracted Android Platform Tools. Open a PowerShell in this directory (Shift + Right\u2010Click)</p> </li> <li> <p>Run the ADP command to list the devices: </p> </li> </ul> <pre><code>.\\adb.exe devices\n</code></pre> <p>You should see something like this:</p> <p></p> <ul> <li>Execute: </li> </ul> <pre><code>.\\adb.exe shell\n</code></pre> <p></p>"},{"location":"robomaster/getting-started/#dji-specific-commands","title":"DJI Specific Commands","text":"<pre><code>dji\ndji_amt_board       dji_derivekey       dji_monitor         dji_verify\ndji_blackbox        dji_hdvt_uav        dji_net.sh          dji_vision\ndji_camera          dji_log_control.sh  dji_network\ndji_chkotp          dji_mb_ctrl         dji_sw_uav\ndji_cpuburn         dji_mb_parser       dji_sys\n</code></pre>"},{"location":"robomaster/getting-started/#checking-ip-address","title":"Checking IP address","text":"<pre><code> ip a\n1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN\n    link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00\n    inet 127.0.0.1/8 scope host lo\n       valid_lft forever preferred_lft forever\n8: rndis0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000\n    link/ether 0a:f8:f6:bb:55:64 brd ff:ff:ff:ff:ff:ff\n    inet 192.168.42.2/24 brd 192.168.42.255 scope global rndis0\n       valid_lft forever preferred_lft forever\n9: wlan0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc pfifo_fast state UP qlen 1000\n    link/ether 60:60:1f:cd:95:f7 brd ff:ff:ff:ff:ff:ff\n    inet 192.168.2.1/24 brd 192.168.2.255 scope global wlan0\n       valid_lft forever preferred_lft forever\n</code></pre>"},{"location":"robomaster/getting-started/#references","title":"References","text":"<ul> <li>Robomaster S1 Videos</li> <li>Robomaster S1 Courses</li> </ul>"},{"location":"robomaster/hack/","title":"Hack","text":"<ul> <li>Robomaster S1 SDK Support.</li> </ul> <p>*** WARNING ***</p> <p>AS IT IS TRUE FOR VIRTUALLY ALL HACKS, THIS HAS THE POTENTIAL TO BREAK YOUR S1 (IT DID NOT BREAK ANY OF MINE BUT I KNEW WHAT I WAS DOING). USE AT YOUR OWN RISK. THERE IS NO IMPLICIT OR EXPLICIT GUARANTEE THAT IT WILL WORK FOR YOU.</p> <p>This is a collection of files and scripts required to get the Robomaster S1 to have access to most functionality provided by the SDK that comes with the Robomaster EP. DJI has so far refused to provide the SDK to S1 owners in an official manner so a non-official one will have to do.</p> <p>This is the full and mostly unmodified SDK as present in th EP (all the changes are related to getting it to work with the S1). It should support everything the EP one supports (I do not have an EP, so I can not be sure) except, of course, for controlling hardware that is only present in the EP.</p> <p>In any case, anything that might not be working can be made to work. Contrary to what DJI want you to believe, the EP is basically just an S1 with extra hardware (there are some other minor differences, but they really do not matter for SDK support).</p> <ul> <li>How to install.</li> </ul> <p>Note this has been designed to work out of the box in Linux. For other platforms you will have to manually replicate the steps in the provided \"upload.sh\" script.</p> <p>1 - Read the \"How to Root - Robomaster S1.pdf\". It is mostly up-to-date except     that the root script used to root the S1 does not work anymore. Instead use     the contents of the \"root.py_s1\" file as the root script. 2 - After you got it to work, have adb installed (as per instructions) and     connect to the S1 using \"adb shell\", open a Terminal window, switch to the     directory where this README and the other files that came with it were     extracted and simply run the upload.sh script. 3 - Restart the S1 (turn it off and on again). When it is booting, you should     hear 2 chimes instead of the usual single chime. This will tell you that it      worked.</p> <ul> <li> <p>New Features</p> </li> <li> <p>v0.0.3 Reenabled adb by default. This convenient in case of issues but it disables rndis (etehrnet over USB) support. If you want to control the S1 with sometyhing connected through USB you will need to comment the adb line in patch.sh (one can still start adb with the root script.</p> </li> <li> <p>v0.0.2 Now scanning QR codes should work again (and we did not lose support for the vision module).</p> </li> <li> <p>v0.0.1 Vision module should now be working correctly with the binary protocol (I actually tested this now for a change).</p> </li> <li> <p>v0.0.0 This now should also support the new DJI binary protocol for the Robomaster EP. This feature was only lightly tested (as due to DJI's handling of all this, I lost interest in the S1 and moved to other more interesting things) but it appears to work even if it is a bit flaky sometimes (specally on initial connection).</p> </li> <li> <p>What is Actually Confirmed Working.</p> </li> </ul> <p>I did not do extensive testing on this, but there are some things I know are definitelly working:</p> <ul> <li>Robomaster app still works and reports the robot as an S1.</li> <li>SDK connections can be made (both text and binary protocols).</li> <li>Getting the robot version works. :)</li> <li>Vision module is working in both protocols (I can get a video stream).</li> </ul> <p>I will try to fix whatever might not be working as long I know it is not working (I have not been using my S1 extensively).</p> <p>That is it, you can try SDK support using some 3rd party libraries like:</p> <p>https://github.com/brunoga/robomaster (Go)  https://github.com/nanmu42/robomasterpy (Python)</p> <p>Official SDK Sample Code Repository:</p> <p>https://github.com/dji-sdk/RoboMaster-SDK</p> <p>Official SDK Documentation:</p> <p>https://robomaster-dev.readthedocs.io/zh_CN/latest/ (In Chinese)</p>"},{"location":"robomaster/images/","title":"Images","text":""},{"location":"tellodrone/","title":"Index","text":""},{"location":"tellodrone/#streaming-tello-video-using-docker-container","title":"Streaming Tello Video using Docker container","text":"<p>Here is an example of a Python script to configure and fetch values from the camera module of a Tello drone:</p> <pre><code>import socket\n\nTELLO_IP = '192.168.10.1'\nTELLO_PORT = 8889\n\n# Create a UDP socket\nsock = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)\nsock.bind(('', TELLO_PORT))\n\n# Configure the camera settings\nsock.sendto(b'command', (TELLO_IP, TELLO_PORT))\nsock.sendto(b'set camera 0', (TELLO_IP, TELLO_PORT))\n\n# Fetch the camera values\nsock.sendto(b'camera?', (TELLO_IP, TELLO_PORT))\n\n# Receive the values from the drone\ndata, server = sock.recvfrom(1518)\n\n# Print the received data\nprint(data.decode(encoding='utf-8'))\n</code></pre> <p>This script uses the socket library in Python to create a UDP socket and send commands to the Tello drone. The script first binds the socket to the Tello's IP address and port, then sends the command command to enter command mode. Next, it sends the set camera 0 command to configure the camera, and finally sends the camera? command to fetch the current camera values. The received data is decoded and printed to the console.</p>"},{"location":"tellodrone/#build-the-docker-image","title":"Build the Docker image:","text":"<pre><code>docker build -t tello-script .\n</code></pre>"},{"location":"tellodrone/#run-the-docker-container","title":"Run the Docker container:","text":"<pre><code>docker run --name tello-container -d tello-script\n</code></pre> <p>This will create a Docker image with the necessary dependencies to run the Python script and run a Docker container from the image. The script will be executed when the container starts.</p>"},{"location":"tellodrone/getting-started/","title":"Getting Started with DJI Tello Drone","text":"<p>Tello is $99 mini-drone that can be programmed using Python, Scratch and Swift. It is rightly called as an indoor quadcopter that comes equipped with an HD camera, giving you a bird\u2019s-eye view of the world. It\u2019s damn easy to fly. Start flying by simply tossing Tello into the air. Slide on your mobile screen to perform 8D flips cool aerial stunts. It\u2019s quite lightweight and dimensions are 3.8 x 3.6 x 1.6 inches, weighing only 2.8 ounces. One of the amazing feature is its VR headset compatibility. You can fly it with a breathtaking first-person view.</p> <p>Tello is a small quadcopter that features a Vision Positioning System and an onboard camera. Tello is a great choice if you want to learn AI analytics at the Edge. Imagine you\u2019re building an application that captures video streaming from the drone and sends it to AI computers like Jetson Xavier or Nano for AI analytics, storing the time-series data in Redis running over Cloud and visualizing it over Grafana. There\u2019s ample amount of learning opportunity using these affordable drones for researchers, engineers and students.</p>"},{"location":"tellodrone/getting-started/#notable-features-of-tello-drone","title":"Notable Features of Tello Drone","text":"<ul> <li>DJI Tello has an excellent flight time of 13 minutes. (enough for your indoor testing!)</li> <li>It comes with a 5MP camera. It can shoot 720p videos, and has digital image stabilization!</li> <li>Approximately 80 g (Propellers and Battery Included) in weight.</li> <li>This small drone has a maximum flight distance of 100 meters and you can fly it in various flight modes using your smartphone or via the Bluetooth controller!</li> </ul> <ul> <li>It has two antennas that make video transmission extra stable and a high-capacity battery that offers impressively long flight times.</li> <li>It comes with a Micro USB Charging Port</li> <li>Equipped with a high-quality image processor, Tello shoots incredible photos and videos. Even if you don\u2019t know how to fly, you can record pro-level videos with EZ Shots and share them on social media from your smartphone.</li> </ul> <ul> <li>Tello comes with sensors that helps it finding obstacles and during the landing</li> </ul> <ul> <li>Tello height can be hacked . Check this out: http://protello.com/tello-hacking-height-limit/</li> <li>DJI Tello has a brushed motor, which is cheaper than the brushless motor, but it\u2019s also less efficient. (Sadly, brushed motors are known to burn out sometimes due to low quality or poor implementation. They\u2019re also susceptible to rough impacts).</li> <li>Being a Non-GPS drone, it is very stable. Video quality is quite decent and landing is also accurate. Also fly it during calm winds or no winds conditions otherwise it\u2019ll sway away with he wind. Good for indoors as well and to click some good selfies.</li> <li>DJI Tello is controlled using an application on an iOS or Android mobile phone. It is also possible to control via Bluetooth joystick connected via application.</li> </ul>"},{"location":"tellodrone/getting-started/#getting-started","title":"Getting Started","text":"<p>Hardware Required:</p> <p></p> <ul> <li>DJI Tello Drone (Buy)</li> <li>Charging Cable</li> <li>Battery (Buy)</li> </ul> <p>DJI Tello comes with a detachable Battery of 1.1Ah/3.8V. Insert the 26g battery into the aircraft and charge the battery by connecting the Micro USB port on the aircraft to a charger.</p>"},{"location":"tellodrone/python/","title":"Control DJI Tello Drone using Python","text":"<p>There are 2 ways you can control your DJI Tello. The first one is using your mobile device, you will need to download Tello or Tello EDU App first. You can also control your Tello via Python or Scratch programming. In this blog, we will see how to control Tello using Python.</p>"},{"location":"tellodrone/python/#pre-requisite","title":"Pre-requisite:","text":"<ul> <li>Linux System( Desktop or Edge device)</li> <li>Python3</li> <li>Tello Mobile app</li> </ul> <p>Press the \u201cPower\u201d button of Tello once. Once it start blinking, open up Tello Android app to discover Tello drone. Open settings and configure WiFi settings like username and password. Connect your laptop to the Tello WiFI network. Follow the below steps to connect via Python script.</p>"},{"location":"tellodrone/python/#install-using-pip","title":"Install using pip","text":"<pre><code>pip install djitellopy\n</code></pre> <p>For Linux distributions with both python2 and python3 (e.g. Debian, Ubuntu, \u2026) you need to run</p> <pre><code>pip3 install djitellopy\n</code></pre>"},{"location":"tellodrone/python/#api-reference","title":"API Reference","text":"<p>See djitellopy.readthedocs.io for a full reference of all classes and methods available.</p>"},{"location":"tellodrone/python/#step-1-connect-takeoff-move-and-land","title":"Step 1. Connect, TakeOff, Move and Land","text":"<p>The below Python script allows you to connect to the drone, take off, make some movement \u2013 Left and Right and then Land smoothly.</p> <pre><code>from djitellopy import Tello\n\ntello = Tello()\n\ntello.connect()\ntello.takeoff()\n\ntello.move_left(100)\ntello.rotate_counter_clockwise(90)\ntello.move_forward(100)\n\ntello.land()\n</code></pre>"},{"location":"tellodrone/python/#step-2-take-a-picture","title":"Step 2. Take a Picture","text":"<pre><code>import cv2\nfrom djitellopy import Tello\n\ntello = Tello()\ntello.connect()\n\ntello.streamon()\nframe_read = tello.get_frame_read()\n\ntello.takeoff()\ncv2.imwrite(\"picture.png\", frame_read.frame)\n\ntello.land()\n</code></pre>"},{"location":"tellodrone/python/#step-3-recording-a-video","title":"Step 3. Recording a Video","text":"<pre><code># source https://github.com/damiafuentes/DJITelloPy\nimport time, cv2\nfrom threading import Thread\nfrom djitellopy import Tello\n\ntello = Tello()\n\ntello.connect()\n\nkeepRecording = True\ntello.streamon()\nframe_read = tello.get_frame_read()\n\ndef videoRecorder():\n    # create a VideoWrite object, recoring to ./video.avi\n\n    height, width, _ = frame_read.frame.shape\n    video = cv2.VideoWriter('video.avi', cv2.VideoWriter_fourcc(*'XVID'), 30, (width, height))\n\n    while keepRecording:\n        video.write(frame_read.frame)\n        time.sleep(1 / 30)\n\n    video.release()\n\n# we need to run the recorder in a seperate thread, otherwise blocking options\n#  would prevent frames from getting added to the video\nrecorder = Thread(target=videoRecorder)\nrecorder.start()\n\ntello.takeoff()\ntello.move_up(100)\ntello.rotate_counter_clockwise(360)\ntello.land()\n\nkeepRecording = False\nrecorder.join()\n</code></pre>"},{"location":"tellodrone/python/#step-4-control-the-drone-using-keyboard","title":"Step 4. Control the drone using Keyboard","text":"<pre><code>from djitellopy import Tello\nimport cv2, math, time\n\ntello = Tello()\ntello.connect()\n\ntello.streamon()\nframe_read = tello.get_frame_read()\n\ntello.takeoff()\n\nwhile True:\n    # In reality you want to display frames in a seperate thread. Otherwise\n    #  they will freeze while the drone moves.\n\n    img = frame_read.frame\n    cv2.imshow(\"drone\", img)\n\n    key = cv2.waitKey(1) &amp; 0xff\n    if key == 27: # ESC\n        break\n    elif key == ord('w'):\n        tello.move_forward(30)\n    elif key == ord('s'):\n        tello.move_back(30)\n    elif key == ord('a'):\n        tello.move_left(30)\n    elif key == ord('d'):\n        tello.move_right(30)\n    elif key == ord('e'):\n        tello.rotate_clockwise(30)\n    elif key == ord('q'):\n        tello.rotate_counter_clockwise(30)\n    elif key == ord('r'):\n        tello.move_up(30)\n    elif key == ord('f'):\n        tello.move_down(30)\ntello.land()\n</code></pre>"}]}