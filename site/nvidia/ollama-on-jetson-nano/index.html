
<!doctype html>
<html lang="en" class="no-js">
  <head>
    
      <meta charset="utf-8">
      <meta name="viewport" content="width=device-width,initial-scale=1">
      
      
      
      
        <link rel="prev" href="../oled-groove-jetson/">
      
      
        <link rel="next" href="../jetson-xavier/">
      
      <link rel="icon" href="../../assets/images/favicon.png">
      <meta name="generator" content="mkdocs-1.4.2, mkdocs-material-9.1.15">
    
    
      
        <title>Ollama on Jetson Nano - IoETPlanet</title>
      
    
    
      <link rel="stylesheet" href="../../assets/stylesheets/main.26e3688c.min.css">
      
      

    
    
    
      
        
        
        <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
        <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Roboto:300,300i,400,400i,700,700i%7CRoboto+Mono:400,400i,700,700i&display=fallback">
        <style>:root{--md-text-font:"Roboto";--md-code-font:"Roboto Mono"}</style>
      
    
    
    <script>__md_scope=new URL("../..",location),__md_hash=e=>[...e].reduce((e,_)=>(e<<5)-e+_.charCodeAt(0),0),__md_get=(e,_=localStorage,t=__md_scope)=>JSON.parse(_.getItem(t.pathname+"."+e)),__md_set=(e,_,t=localStorage,a=__md_scope)=>{try{t.setItem(a.pathname+"."+e,JSON.stringify(_))}catch(e){}}</script>
    
      

    
    
    
  </head>
  
  
    <body dir="ltr">
  
    
    
      <script>var palette=__md_get("__palette");if(palette&&"object"==typeof palette.color)for(var key of Object.keys(palette.color))document.body.setAttribute("data-md-color-"+key,palette.color[key])</script>
    
    <input class="md-toggle" data-md-toggle="drawer" type="checkbox" id="__drawer" autocomplete="off">
    <input class="md-toggle" data-md-toggle="search" type="checkbox" id="__search" autocomplete="off">
    <label class="md-overlay" for="__drawer"></label>
    <div data-md-component="skip">
      
        
        <a href="#pre-requisite" class="md-skip">
          Skip to content
        </a>
      
    </div>
    <div data-md-component="announce">
      
    </div>
    
    
      

  

<header class="md-header md-header--shadow" data-md-component="header">
  <nav class="md-header__inner md-grid" aria-label="Header">
    <a href="../.." title="IoETPlanet" class="md-header__button md-logo" aria-label="IoETPlanet" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    <label class="md-header__button md-icon" for="__drawer">
      <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M3 6h18v2H3V6m0 5h18v2H3v-2m0 5h18v2H3v-2Z"/></svg>
    </label>
    <div class="md-header__title" data-md-component="header-title">
      <div class="md-header__ellipsis">
        <div class="md-header__topic">
          <span class="md-ellipsis">
            IoETPlanet
          </span>
        </div>
        <div class="md-header__topic" data-md-component="header-topic">
          <span class="md-ellipsis">
            
              Ollama on Jetson Nano
            
          </span>
        </div>
      </div>
    </div>
    
    
    
      <label class="md-header__button md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
      </label>
      <div class="md-search" data-md-component="search" role="dialog">
  <label class="md-search__overlay" for="__search"></label>
  <div class="md-search__inner" role="search">
    <form class="md-search__form" name="search">
      <input type="text" class="md-search__input" name="query" aria-label="Search" placeholder="Search" autocapitalize="off" autocorrect="off" autocomplete="off" spellcheck="false" data-md-component="search-query" required>
      <label class="md-search__icon md-icon" for="__search">
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M9.5 3A6.5 6.5 0 0 1 16 9.5c0 1.61-.59 3.09-1.56 4.23l.27.27h.79l5 5-1.5 1.5-5-5v-.79l-.27-.27A6.516 6.516 0 0 1 9.5 16 6.5 6.5 0 0 1 3 9.5 6.5 6.5 0 0 1 9.5 3m0 2C7 5 5 7 5 9.5S7 14 9.5 14 14 12 14 9.5 12 5 9.5 5Z"/></svg>
        <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M20 11v2H8l5.5 5.5-1.42 1.42L4.16 12l7.92-7.92L13.5 5.5 8 11h12Z"/></svg>
      </label>
      <nav class="md-search__options" aria-label="Search">
        
        <button type="reset" class="md-search__icon md-icon" title="Clear" aria-label="Clear" tabindex="-1">
          <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M19 6.41 17.59 5 12 10.59 6.41 5 5 6.41 10.59 12 5 17.59 6.41 19 12 13.41 17.59 19 19 17.59 13.41 12 19 6.41Z"/></svg>
        </button>
      </nav>
      
    </form>
    <div class="md-search__output">
      <div class="md-search__scrollwrap" data-md-scrollfix>
        <div class="md-search-result" data-md-component="search-result">
          <div class="md-search-result__meta">
            Initializing search
          </div>
          <ol class="md-search-result__list" role="presentation"></ol>
        </div>
      </div>
    </div>
  </div>
</div>
    
    
  </nav>
  
</header>
    
    <div class="md-container" data-md-component="container">
      
      
        
          
        
      
      <main class="md-main" data-md-component="main">
        <div class="md-main__inner md-grid">
          
            
              
              <div class="md-sidebar md-sidebar--primary" data-md-component="sidebar" data-md-type="navigation" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    


<nav class="md-nav md-nav--primary" aria-label="Navigation" data-md-level="0">
  <label class="md-nav__title" for="__drawer">
    <a href="../.." title="IoETPlanet" class="md-nav__button md-logo" aria-label="IoETPlanet" data-md-component="logo">
      
  
  <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><path d="M12 8a3 3 0 0 0 3-3 3 3 0 0 0-3-3 3 3 0 0 0-3 3 3 3 0 0 0 3 3m0 3.54C9.64 9.35 6.5 8 3 8v11c3.5 0 6.64 1.35 9 3.54 2.36-2.19 5.5-3.54 9-3.54V8c-3.5 0-6.64 1.35-9 3.54Z"/></svg>

    </a>
    IoETPlanet
  </label>
  
  <ul class="md-nav__list" data-md-scrollfix>
    
      
      
      

  
  
  
    <li class="md-nav__item">
      <a href="../.." class="md-nav__link">
        Home
      </a>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2" >
      
      
      
        <label class="md-nav__link" for="__nav_2" id="__nav_2_label" tabindex="0">
          Raspberry Pi
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_2_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2">
          <span class="md-nav__icon md-icon"></span>
          Raspberry Pi
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../raspberrypi/getting-started/" class="md-nav__link">
        Getting Started
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../raspberrypi/docker-on-raspberrypi/" class="md-nav__link">
        Installing Docker on Raspberry Pi
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_2_3" >
      
      
      
        <label class="md-nav__link" for="__nav_2_3" id="__nav_2_3_label" tabindex="0">
          Projects
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_2_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_2_3">
          <span class="md-nav__icon md-icon"></span>
          Projects
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../raspberrypi/projects/Pico/" class="md-nav__link">
        Pico Project
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../raspberrypi/projects/GPS/getting-started/" class="md-nav__link">
        Using GPS
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
    
  
  
    
    <li class="md-nav__item md-nav__item--active md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3" checked>
      
      
      
        <label class="md-nav__link" for="__nav_3" id="__nav_3_label" tabindex="0">
          NVIDIA Jetson Nano
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_3_label" aria-expanded="true">
        <label class="md-nav__title" for="__nav_3">
          <span class="md-nav__icon md-icon"></span>
          NVIDIA Jetson Nano
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../getting-started/" class="md-nav__link">
        Getting Started
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../docker-on-jetson-nano/" class="md-nav__link">
        Installing Docker on NVIDIA Jetson
      </a>
    </li>
  

            
          
            
              
  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_3_3" >
      
      
      
        <label class="md-nav__link" for="__nav_3_3" id="__nav_3_3_label" tabindex="0">
          Projects
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="2" aria-labelledby="__nav_3_3_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_3_3">
          <span class="md-nav__icon md-icon"></span>
          Projects
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../redis-grafana-docker/" class="md-nav__link">
        BME Sensor Analytics using Redis TimeSeries, Grafana and Docker
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../bme680-jetson-neo4j.md" class="md-nav__link">
        BME Sensor Analytics using Neo4j, Grafana and Docker
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../oled-groove-jetson/" class="md-nav__link">
        OLED Display using Groove Hat on Jetson Nano
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

            
          
            
              
  
  
    
  
  
    <li class="md-nav__item md-nav__item--active">
      
      <input class="md-nav__toggle md-toggle" type="checkbox" id="__toc">
      
      
      
        <label class="md-nav__link md-nav__link--active" for="__toc">
          Ollama on Jetson Nano
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <a href="./" class="md-nav__link md-nav__link--active">
        Ollama on Jetson Nano
      </a>
      
        

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pre-requisite" class="md-nav__link">
    Pre-requisite
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#software" class="md-nav__link">
    Software
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#preparing-your-jetson-nano" class="md-nav__link">
    Preparing Your Jetson Nano
  </a>
  
    <nav class="md-nav" aria-label="Preparing Your Jetson Nano">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#step-0-verify-the-jetson-device" class="md-nav__link">
    Step 0. Verify the Jetson device
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-1-update-the-apt-repository" class="md-nav__link">
    Step 1. Update the APT repository
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-install-the-curl-package" class="md-nav__link">
    Step 2. Install the curl package
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-install-ollama" class="md-nav__link">
    Step 3. Install Ollama
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-4-explore-the-ollama-cli" class="md-nav__link">
    Step 4. Explore the Ollama CLI
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-5-list-available-models" class="md-nav__link">
    Step 5. List Available Models
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-6-run-a-model" class="md-nav__link">
    Step 6. Run a model
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#integrating-open-webui-with-ollama" class="md-nav__link">
    Integrating Open WebUI with Ollama
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#step-1-stop-the-ollama-service" class="md-nav__link">
    Step 1: Stop the Ollama Service
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#step-2-run-ollama-with-docker" class="md-nav__link">
    Step 2. Run Ollama with Docker
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#step-3-run-open-webui" class="md-nav__link">
    Step 3. Run Open WebUI
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#step-4-verify-running-containers" class="md-nav__link">
    Step 4. Verify Running Containers
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#results" class="md-nav__link">
    Results:
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bundled-installation-of-open-webui-with-ollama" class="md-nav__link">
    Bundled Installation of Open WebUI with Ollama
  </a>
  
    <nav class="md-nav" aria-label="Bundled Installation of Open WebUI with Ollama">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#using-gpu" class="md-nav__link">
    Using GPU
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-cpu-only" class="md-nav__link">
    Using CPU only
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    Conclusion
  </a>
  
</li>
      
    </ul>
  
</nav>
      
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_4" >
      
      
      
        <label class="md-nav__link" for="__nav_4" id="__nav_4_label" tabindex="0">
          NVIDIA AGX Xavier
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_4_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_4">
          <span class="md-nav__icon md-icon"></span>
          NVIDIA AGX Xavier
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../jetson-xavier/" class="md-nav__link">
        Getting Started
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../docker-on-xavier/" class="md-nav__link">
        Installing Docker on NVIDIA Jetson Xavier
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_5" >
      
      
      
        <label class="md-nav__link" for="__nav_5" id="__nav_5_label" tabindex="0">
          DJI Tello Drone
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_5_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_5">
          <span class="md-nav__icon md-icon"></span>
          DJI Tello Drone
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tellodrone/getting-started/" class="md-nav__link">
        Getting Started
      </a>
    </li>
  

            
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../tellodrone/python/" class="md-nav__link">
        Using Python
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
      
      
      

  
  
  
    
    <li class="md-nav__item md-nav__item--nested">
      
      
      
      
      <input class="md-nav__toggle md-toggle " type="checkbox" id="__nav_6" >
      
      
      
        <label class="md-nav__link" for="__nav_6" id="__nav_6_label" tabindex="0">
          DJI Robomaster
          <span class="md-nav__icon md-icon"></span>
        </label>
      
      <nav class="md-nav" data-md-level="1" aria-labelledby="__nav_6_label" aria-expanded="false">
        <label class="md-nav__title" for="__nav_6">
          <span class="md-nav__icon md-icon"></span>
          DJI Robomaster
        </label>
        <ul class="md-nav__list" data-md-scrollfix>
          
            
              
  
  
  
    <li class="md-nav__item">
      <a href="../../robomaster/getting-started/" class="md-nav__link">
        Getting Started
      </a>
    </li>
  

            
          
        </ul>
      </nav>
    </li>
  

    
  </ul>
</nav>
                  </div>
                </div>
              </div>
            
            
              
              <div class="md-sidebar md-sidebar--secondary" data-md-component="sidebar" data-md-type="toc" >
                <div class="md-sidebar__scrollwrap">
                  <div class="md-sidebar__inner">
                    

<nav class="md-nav md-nav--secondary" aria-label="Table of contents">
  
  
  
  
    <label class="md-nav__title" for="__toc">
      <span class="md-nav__icon md-icon"></span>
      Table of contents
    </label>
    <ul class="md-nav__list" data-md-component="toc" data-md-scrollfix>
      
        <li class="md-nav__item">
  <a href="#pre-requisite" class="md-nav__link">
    Pre-requisite
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#software" class="md-nav__link">
    Software
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#preparing-your-jetson-nano" class="md-nav__link">
    Preparing Your Jetson Nano
  </a>
  
    <nav class="md-nav" aria-label="Preparing Your Jetson Nano">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#step-0-verify-the-jetson-device" class="md-nav__link">
    Step 0. Verify the Jetson device
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-1-update-the-apt-repository" class="md-nav__link">
    Step 1. Update the APT repository
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-2-install-the-curl-package" class="md-nav__link">
    Step 2. Install the curl package
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-3-install-ollama" class="md-nav__link">
    Step 3. Install Ollama
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-4-explore-the-ollama-cli" class="md-nav__link">
    Step 4. Explore the Ollama CLI
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-5-list-available-models" class="md-nav__link">
    Step 5. List Available Models
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#step-6-run-a-model" class="md-nav__link">
    Step 6. Run a model
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#integrating-open-webui-with-ollama" class="md-nav__link">
    Integrating Open WebUI with Ollama
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#step-1-stop-the-ollama-service" class="md-nav__link">
    Step 1: Stop the Ollama Service
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#step-2-run-ollama-with-docker" class="md-nav__link">
    Step 2. Run Ollama with Docker
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#step-3-run-open-webui" class="md-nav__link">
    Step 3. Run Open WebUI
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#step-4-verify-running-containers" class="md-nav__link">
    Step 4. Verify Running Containers
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#results" class="md-nav__link">
    Results:
  </a>
  
</li>
      
        <li class="md-nav__item">
  <a href="#bundled-installation-of-open-webui-with-ollama" class="md-nav__link">
    Bundled Installation of Open WebUI with Ollama
  </a>
  
    <nav class="md-nav" aria-label="Bundled Installation of Open WebUI with Ollama">
      <ul class="md-nav__list">
        
          <li class="md-nav__item">
  <a href="#using-gpu" class="md-nav__link">
    Using GPU
  </a>
  
</li>
        
          <li class="md-nav__item">
  <a href="#using-cpu-only" class="md-nav__link">
    Using CPU only
  </a>
  
</li>
        
      </ul>
    </nav>
  
</li>
      
        <li class="md-nav__item">
  <a href="#conclusion" class="md-nav__link">
    Conclusion
  </a>
  
</li>
      
    </ul>
  
</nav>
                  </div>
                </div>
              </div>
            
          
          
            <div class="md-content" data-md-component="content">
              <article class="md-content__inner md-typeset">
                
                  


  <h1>Ollama on Jetson Nano</h1>

<p>NVIDIA Jetson devices are powerful platforms designed for edge AI applications, offering excellent GPU acceleration capabilities to run compute-intensive tasks like language model inference. </p>
<p>With official support for NVIDIA Jetson devices, Ollama brings the ability to manage and serve Large Language Models (LLMs) locally, ensuring privacy, performance, and offline operation. By integrating Open WebUI, you can enhance your workflow with an intuitive web interface for managing these models.</p>
<p>This guide will walk you through setting up Ollama on your Jetson device, integrating it with Open WebUI, and configuring the system for optimal GPU utilization. Whether you're a developer or an AI enthusiast, this setup allows you to harness the full potential of LLMs right on your Jetson device.</p>
<h2 id="pre-requisite">Pre-requisite</h2>
<ol>
<li><a href="https://developer.nvidia.com/embedded/jetson-nano">Jetson Nano</a></li>
<li>A 5V 4Ampere Charger</li>
<li>64GB SD card</li>
<li>WiFi Adapter</li>
<li>Wireless Keyboard</li>
<li>Wireless mouse</li>
</ol>
<p><img alt="Image32" src="https://dev-to-uploads.s3.amazonaws.com/uploads/articles/cw8ms0ek90od5rrhd0uv.png" /></p>
<h2 id="software">Software</h2>
<ul>
<li>Download Jetson SD card image from <a href="https://developer.nvidia.com/embedded/downloads">this link</a></li>
<li>Raspberry Pi Imager installed on your local system</li>
</ul>
<h2 id="preparing-your-jetson-nano">Preparing Your Jetson Nano</h2>
<ol>
<li>Unzip the SD card image</li>
<li>Insert SD card into your system.</li>
<li>Bring up Raspberry Pi Imager tool to flash image into the SD card</li>
</ol>
<h3 id="step-0-verify-the-jetson-device">Step 0. Verify the Jetson device</h3>
<p><img alt="Image1" src="https://dev-to-uploads.s3.amazonaws.com/uploads/articles/rar7xc470wz6m9wk6nu0.png" /></p>
<p>Begin by verifying the L4T (Linux for Tegra) version on your Jetson device. Each Jetson platform runs a specific JetPack version tied to an L4T release. To check your configuration:</p>
<pre><code>cat /etc/nv_tegra_release
# R32 (release), REVISION: 7.1, GCID: 29818004, BOARD: t210ref, EABI: aarch64, DATE: Sat Feb 19 17:05:08 UTC 2022
</code></pre>
<p>This output confirms the device is using L4T R32.7.1, compatible with JetPack 4.6.1. Ensure your Jetson device is updated to the latest supported L4T version to avoid compatibility issues.</p>
<h3 id="step-1-update-the-apt-repository">Step 1. Update the APT repository</h3>
<p>Ensure your system is up to date to avoid errors during the installation of dependencies:</p>
<pre><code>sudo apt update
</code></pre>
<h3 id="step-2-install-the-curl-package">Step 2. Install the curl package</h3>
<p>The Ollama installation script requires curl to fetch and execute:</p>
<pre><code>sudo apt install curl
</code></pre>
<h3 id="step-3-install-ollama">Step 3. Install Ollama</h3>
<p>Install Ollama using its official installation script, which automatically sets up the required services and permissions:</p>
<pre><code>curl -fsSL https://ollama.com/install.sh | sh
</code></pre>
<pre><code>&gt;&gt;&gt; Adding ollama user to video group...
&gt;&gt;&gt; Adding current user to ollama group...
&gt;&gt;&gt; Creating ollama systemd service...
&gt;&gt;&gt; Enabling and starting ollama service...
Created symlink /etc/systemd/system/default.target.wants/ollama.service → /etc/systemd/system/ollama.service.
&gt;&gt;&gt; NVIDIA JetPack ready.
&gt;&gt;&gt; The Ollama API is now available at 127.0.0.1:11434.
&gt;&gt;&gt; Install complete. Run &quot;ollama&quot; from the command line.
</code></pre>
<p>Ollama is now ready to run locally, leveraging your Jetson’s GPU for efficient LLM inference.</p>
<h3 id="step-4-explore-the-ollama-cli">Step 4. Explore the  Ollama CLI</h3>
<p>Ollama provides a CLI to manage and interact with models. To view available commands:</p>
<pre><code>ollama
Usage:
  ollama [flags]
  ollama [command]

Available Commands:
  serve       Start ollama
  create      Create a model from a Modelfile
  show        Show information for a model
  run         Run a model
  stop        Stop a running model
  pull        Pull a model from a registry
  push        Push a model to a registry
  list        List models
  ps          List running models
  cp          Copy a model
  rm          Remove a model
  help        Help about any command

Flags:
  -h, --help      help for ollama
  -v, --version   Show version information

Use &quot;ollama [command] --help&quot; for more information about a command.
</code></pre>
<h3 id="step-5-list-available-models">Step 5. List Available Models</h3>
<p>Check the preloaded models available in Ollama:</p>
<pre><code>$ ollama list
NAME                     ID              SIZE      MODIFIED
llama3:latest            365c0bd3c000    4.7 GB    4 weeks ago
codellama:latest         8fdf8f752f6e    3.8 GB    4 months ago
codellama:7b-instruct    8fdf8f752f6e    3.8 GB    4 months ago
llama3:8b                365c0bd3c000    4.7 GB    4 months ago
mistral:latest           61e88e884507    4.1 GB    9 months ago
llama2:latest            78e26419b446    3.8 GB    10 months ago
</code></pre>
<h3 id="step-6-run-a-model">Step 6. Run a model</h3>
<p>Run the llama3 model and perform tasks like generating Python code:</p>
<pre><code>ollama run llama3
&gt;&gt;&gt; &gt; Can you write a Python script to calculate the factorial of a number?
Sure! Here’s the code:

def factorial(n):
    if n == 0 or n == 1:
        return 1
    else:
        return n * factorial(n - 1)

num = int(input(&quot;Enter a number: &quot;))
print(f&quot;The factorial of {num} is {factorial(num)}&quot;)
</code></pre>
<h2 id="integrating-open-webui-with-ollama">Integrating Open WebUI with Ollama</h2>
<p>Open WebUI complements Ollama by providing an intuitive web-based interface to manage and interact with LLMs.</p>
<h2 id="step-1-stop-the-ollama-service">Step 1: Stop the Ollama Service</h2>
<p>Before proceeding, stop the system-wide Ollama service to avoid conflicts when running it in Docker:</p>
<pre><code>sudo systemctl disable ollama
</code></pre>
<h2 id="step-2-run-ollama-with-docker">Step 2. Run Ollama with Docker</h2>
<p>Deploy Ollama as a Docker container with GPU support:</p>
<pre><code>sudo docker run -d --gpus=all --runtime=nvidia -v ollama:/root/.ollama -p 11434:11434 --name ollama ollama/ollama

</code></pre>
<h2 id="step-3-run-open-webui">Step 3. Run Open WebUI</h2>
<p>Run Open WebUI with GPU acceleration in a separate Docker container:</p>
<pre><code>sudo docker run -d -p 3000:8080 --gpus all --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:cuda
</code></pre>
<h2 id="step-4-verify-running-containers">Step 4. Verify Running Containers</h2>
<p>Ensure both Ollama and Open WebUI containers are running correctly:</p>
<pre><code>sudo docker ps
CONTAINER ID   IMAGE                                COMMAND               CREATED          STATUS                            PORTS                                           NAMES
dee2d1fbe4cf   ghcr.io/open-webui/open-webui:cuda   &quot;bash start.sh&quot;       10 seconds ago   Up 6 seconds (health: starting)   0.0.0.0:3000-&gt;8080/tcp, :::3000-&gt;8080/tcp       open-webui
9fd89a4fa908   ollama/ollama                        &quot;/bin/ollama serve&quot;   52 seconds ago   Up 48 seconds                     0.0.0.0:11434-&gt;11434/tcp, :::11434-&gt;11434/tcp   ollama
</code></pre>
<h2 id="results">Results:</h2>
<pre><code>cuda: Pulling from open-webui/open-webui
6d29a096dd42: Pull complete
6fab32a80202: Pull complete
610eb561c31b: Pull complete
50c0fb1f456e: Pull complete
ae5672aeb8ae: Pull complete
4f4fb700ef54: Pull complete
639718444375: Pull complete
5dcf97af08b1: Pull complete
ea9079f84622: Pull complete
e3fc97a4f07a: Pull complete
a538afa31f12: Pull complete
86ede3d9066a: Pull complete
a5aa461a25d1: Pull complete
6acc9cdc9b03: Pull complete
1920af2d5f9d: Pull complete
Digest: sha256:781acd8f2b45bdf45ac9a89fa80d52a6a966d9e1e7b55fbb5f0f1397ce5d9515
Status: Downloaded newer image for ghcr.io/open-webui/open-webui:cuda
843100c8d64d0ab9ea78fd64f4ffced0a62ce8783c850ce66d7ebb890f102e5a
</code></pre>
<pre><code>ajeetraina@ajeetraina-desktop:~$ sudo docker ps
[sudo] password for ajeetraina:
CONTAINER ID   IMAGE                                COMMAND           CREATED         STATUS                     PORTS                                       NAMES
843100c8d64d   ghcr.io/open-webui/open-webui:cuda   &quot;bash start.sh&quot;   4 minutes ago   Up 4 minutes (unhealthy)   0.0.0.0:3000-&gt;8080/tcp, :::3000-&gt;8080/tcp   open-webui
</code></pre>
<h2 id="bundled-installation-of-open-webui-with-ollama">Bundled Installation of Open WebUI with Ollama</h2>
<p>For a simplified setup, you can use a bundled Docker image that integrates both Open WebUI and Ollama.</p>
<h3 id="using-gpu">Using GPU</h3>
<p>This installation method uses a single container image that bundles Open WebUI with Ollama, allowing for a streamlined setup via a single command. Choose the appropriate command based on your hardware setup:</p>
<pre><code>sudo docker run -d -p 3000:8080 --gpus=all -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama
</code></pre>
<h3 id="using-cpu-only">Using CPU only</h3>
<p>For CPU Only: If you're not using a GPU, use this command instead:</p>
<pre><code>sudo docker run -d -p 3000:8080 -v ollama:/root/.ollama -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:ollama
</code></pre>
<p>Both commands facilitate a built-in, hassle-free installation of both Open WebUI and Ollama, ensuring that you can get everything up and running swiftly.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Once configured, Open WebUI can be accessed at http://localhost:3000, while Ollama operates at http://localhost:11434. This setup provides a seamless and GPU-accelerated environment for running and managing LLMs locally on NVIDIA Jetson devices.</p>
<p>This guide showcases the power and versatility of NVIDIA Jetson devices when paired with Ollama and Open WebUI, enabling advanced AI workloads at the edge with ease and efficiency.</p>





                
              </article>
            </div>
          
          
        </div>
        
      </main>
      
        <footer class="md-footer">
  
  <div class="md-footer-meta md-typeset">
    <div class="md-footer-meta__inner md-grid">
      <div class="md-copyright">
  
  
    Made with
    <a href="https://squidfunk.github.io/mkdocs-material/" target="_blank" rel="noopener">
      Material for MkDocs
    </a>
  
</div>
      
    </div>
  </div>
</footer>
      
    </div>
    <div class="md-dialog" data-md-component="dialog">
      <div class="md-dialog__inner md-typeset"></div>
    </div>
    
    <script id="__config" type="application/json">{"base": "../..", "features": [], "search": "../../assets/javascripts/workers/search.208ed371.min.js", "translations": {"clipboard.copied": "Copied to clipboard", "clipboard.copy": "Copy to clipboard", "search.result.more.one": "1 more on this page", "search.result.more.other": "# more on this page", "search.result.none": "No matching documents", "search.result.one": "1 matching document", "search.result.other": "# matching documents", "search.result.placeholder": "Type to start searching", "search.result.term.missing": "Missing", "select.version": "Select version"}}</script>
    
    
      <script src="../../assets/javascripts/bundle.b4d07000.min.js"></script>
      
    
  </body>
</html>